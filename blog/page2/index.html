<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      cgranade::space &middot; Quantum, stats, programming, and some rants
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- JavaScript -->
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: {
        Macros: {
          ket: ["\\left| #1\\right\\rangle", 1]
        }
      }
    });
  </script>
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          cgranade::<br>space
        </a>
      </h1>
      <p class="lead"></p>
      <p class="lead">Quantum information • Statistical inference • Scientific programming</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>

      

      
      

      <a class="sidebar-nav-item" href="/cv.html">CV</a>
      <a class="sidebar-nav-item" href="/research/">Research</a>
      <a class="sidebar-nav-item" href="/projects.html">Projects</a>
      <a class="sidebar-nav-item active" href="/blog/">Blog</a>
      <a class="sidebar-nav-item" href="/faq.html">FAQ</a>
      <a class="sidebar-nav-item" href="/contact.html">Contact</a>


      

      <a class="sidebar-nav-item" href="https://github.com/cgranade/cgranade.github.io">GitHub project</a>
    </nav>

    <p>&copy; 2023. Licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a>
       except where otherwise noted.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/2019/09/14/qc-looking-sharp.html">
        Quantum Computing: Looking Sharp
      </a>
    </h1>

    <span class="post-date">14 Sep 2019</span>

    <p>Last week, I took a look at what a quantum state is in the context of quantum development, using Q# to get a handle on things.
Today, though, I’d like to take a little step back and look at what Q# is in the first place, as well as some things that Q# is <strong>not</strong>.</p>

<h2 id="q-is-a-programming-langauge">Q# is a Programming Langauge</h2>

<p>When you get right down to it, quantum programs are classical programs that tell a quantum computer what to do.
After all, we want to be able to work with classical data, and to get classical data back out from our quantum computers.</p>

<p>From that perspective, then, it’s really important that Q# is a programming language.
For instance, a traditional “hello, world” application looks pretty much how you might expect a “hello, world” application to look:</p>

<pre><code class="language-Q#">namespace HelloWorld {
    open Microsoft.Quantum.Intrinsic;

    /// # Summary
    /// Says hello to the world.
    function Hello() : Unit {
        Message("Hello, world!");
    }
}
</code></pre>

<p>As a programming language, Q# builds on the long history of classical programming languages to make it as easy as possible to write quantum programs as well.
For example, throughout the history of classical programming, we’ve learned that features like namespaces and API documentation comments help us organizing and understanding our code; we can already see both features on display here in our “Hello, world” Q# program.</p>

<h2 id="q-is-a-domain-specific-language">Q# is a Domain-Specific Language</h2>

<p>Given that Q# is “just” a programming language, one might then ask why it exists at all.
We could in principle write our quantum programs in existing classical languages like Python, C#, Java, JavaScript, and so forth.
That said, each language we work with in software development is engineered to be good at different tasks, and to focus on different domains.</p>

<p>Q# is distinct from other programming languages in that it is designed from the first step to be great at writing quantum programs.
This means that Q# makes some choices as to what features to include and which features to leave out that are unusual for general-purpose classical languages, but that make it really easy to write rich quantum programs.</p>

<p>For example, since quantum mechanics is reversible, one common pattern in quantum programming is to run a subroutine <em>backwards</em>.
We may want to write a program that converts some quantum data into a representation where it’s easier to do a particular calculation, do that calculation, then undo our first transformation.
In Q#, this is supported by the <code class="language-plaintext highlighter-rouge">Adjoint</code> keyword, which represents the inverse of an operation.
Just as we can run <a href="https://docs.microsoft.com/qsharp/api/qsharp/microsoft.quantum.preparation.prepareentangledstate"><code class="language-plaintext highlighter-rouge">PrepareEntangledState</code></a> to entangle the state of some qubits, we can run <code class="language-plaintext highlighter-rouge">Adjoint PrepareEntangledState</code> to measure out that entanglement.</p>

<p>In order to support the <code class="language-plaintext highlighter-rouge">Adjoint</code> keyword, we need a few things to be true about our quantum programs:</p>

<ul>
  <li>Loops can’t exit early, otherwise we couldn’t reverse the direction of a loop.</li>
  <li>Classical calculations used in a reversible operation need to be deterministic.</li>
  <li>Classical computations used in a reversible operation can’t have side effects.</li>
</ul>

<p>To ensure these are all true, <code class="language-plaintext highlighter-rouge">for</code> loops work a bit differently in Q#, and there’s a difference between functions (which are always deterministic), and operations (which may have side effects, including sending instructions to a quantum device).
These choices made with the design of Q# help make it a perfect fit for what we need a quantum programming language to do.</p>

<p>If you’re interested in learning more about why we need Q#, check out <a href="https://devblogs.microsoft.com/qsharp/why-do-we-need-q/">Alan Geller’s post on the Q# dev blog</a>.</p>

<h2 id="q-includes-classical-logic">Q# Includes Classical Logic</h2>

<p>All the above being said, many quantum programs also include a lot of traditional, classical computation that has to work in close tandem with a quantum device.
From finding the right rotation angles to describe a quantum simulation task, through to using measurement data from a quantum device to decide the next measurement that you should do, quantum programming is rife with classical computational tasks.</p>

<p>This means that Q# has to not only be great at sending instructions to a quantum computer, but also at the kind of classical computations that need to run alongside a quantum device.
As a result, Q# includes a lot of features like <a href="https://docs.microsoft.com/quantum/language/type-model#user-defined-types">user-defined types</a> and <a href="https://docs.microsoft.com/qsharp/api/qsharp/microsoft.quantum.canon">functional programming libraries</a> to help you write <em>classical</em> logic in your quantum programs.</p>

<h2 id="q-is-not-a-circuit-language">Q# is <strong>Not</strong> a Circuit Language</h2>

<p>It’s pretty common when talking about quantum programming to focus on a particular kind of quantum program called a <em>circuit</em>.
By analogy to a classical logic circuit, which describes how a bunch of different classical logic gates are connected to each other, a quantum circuit expresses a quantum program as a sequence of quantum gates.</p>

<p>This view has been really useful in quantum computing research for many years, but it has some problems that make it hard to use for developing quantum programs.
The most critical problem with thinking in terms of quantum circuits is that it’s really difficult to incorporate classical logic into a circuit diagram.
Classical logic circuits and quantum circuits are at best rough analogies to each other, and don’t really mix together.
By contrast, classical logic is really easy to write out.</p>

<p>For example, in quantum teleportation (a fancy and whimsical name for a neat way to move quantum data around), we need to apply quantum instructions based on the result of some measurements.
This is <a href="https://github.com/microsoft/Quantum/blob/master/Samples/src/Teleportation/TeleportationSample.qs">really easy to write in Q#</a>:</p>

<pre><code class="language-Q#">if (MResetZ(msg) == One)      { Z(target); }
if (MResetZ(register) == One) { X(target); }
</code></pre>

<p>This works because Q# isn’t a circuit description language, but something much more powerful: a language for expressing quantum algorithms in terms of quantum programs.</p>

<h2 id="you-dont-need-to-know-c-to-use-q">You <strong>Don’t</strong> Need to Know C# to Use Q#</h2>

<p>Taking a turn for a moment, you might guess from the fact that “sharp” is right there in the name “Q#” that you need to know C# and .NET development to use Q#.
After all, over the 17 years that .NET has been around, “sharp” has become a pretty traditional indicator that something is a part of the .NET ecosystem: F#, SharpDevelop, Resharper, Gtk#, even A#, J#, P#, and X#!</p>

<p>In the case of Q#, though, what that “sharp” tells you is that Q# is built from and plays well with the .NET ecosystem.
Just as Q# has learned from the history of classical programming languages, Q# reuses a lot of .NET infrastructure like the NuGet package manager to make it easy easy as possible to write powerful quantum applications.
That doesn’t mean, however, you have to use C# or other .NET languages to write Q#.</p>

<p>Indeed, Q# <a href="https://docs.microsoft.com/quantum/install-guide/python">provides interoperability with Python</a>, making it easy to include Q# programs as a part of your data science or research workflow.
Q# can even be used entirely on its own from within Jupyter Notebook, thanks to the <a href="https://docs.microsoft.com/quantum/install-guide/jupyter">IQ# kernel for Jupyter</a>.</p>

<p>Even if you <em>want</em> to use Q# with the cross-platform open-source .NET Core SDK, that doesn’t mean you need to be a C# expert.
It’s easy to use <a href="https://github.com/microsoft/Quantum/tree/master/Samples/src/FSharpWithQSharp">Q# from F#</a>, <a href="https://github.com/tcNickolas/MiscQSharp/blob/master/Quantum_VBNet/README.md#using-q-with-visual-basic-net">Visual Basic .NET</a>, and even <a href="https://www.cgranade.com/blog/2018/12/03/getting-posh-with-qsharp.html">PowerShell</a> as well.
If you’re new to .NET entirely, the project templates, <a href="https://marketplace.visualstudio.com/items?itemName=quantum.quantum-devkit-vscode">Visual Studio Code</a> and <a href="https://marketplace.visualstudio.com/items?itemName=quantum.DevKit">Visual Studio 2019</a> extensions, and the Quantum Development Kit samples all make it really easy to use Q# with .NET.</p>

<p>When it comes down to it, Q# is meant to write quantum programs that work well with existing classical platforms.
Whether you’re a seasoned C# developer, or a die-hard Pythonista, whether you’re new to programming, or have been at this for a while, I encourage you to give Q# a try.</p>

<h2 id="you-dont-need-to-know-quantum-computing-to-get-started-with-q">You <strong>Don’t</strong> Need to Know Quantum Computing to Get Started with Q#</h2>

<p>OK, so you don’t have to be a .NET developer to start writing quantum programs, but surely you have to at least be pretty good at this quantum stuff, right?
Not really, as it turns out!</p>

<p>One of the most amazing things that has happened to quantum computing in the past few years is that it has gotten much easier to jump in, and to learn by doing.
Five or ten years ago, your best bet for getting involved with quantum computing probably would have started by reading a textbook and  writing down a bunch of matrices, and probably even taking some graduate-level classes.
That’s still a great way to learn, but there’s a lot of other really good paths to learning quantum computing as well thanks to how much easier it has gotten to write and run quantum programs on your laptop or on the web.
Using tools like Q# and the Quantum Development Kit, you can try out your understanding by writing a quantum program, then you can <em>run</em> that program to see if it matched with your understanding.</p>

<p>The ability to quickly get feedback like this has really broadened the set of skills that can help you understand quantum computing.
The quantum computing community is bigger now than it ever has been, not just in terms of the number of people, but also in terms of the kinds of backgrounds that people bring with them to the community, the diversity of people in the community, and the ways of thinking about quantum computing.</p>

<p>Given that, if you’re looking to use Q# to learn quantum computing, where should you start?
I’m definitely partial to <a href="http://bit.ly/qsharp-book">my own book</a>, of course (new chapters coming soon!), but there’s a lot more out there as well.
Check out <a href="https://qsharp.community">qsharp.community</a> for a great list!</p>

<p>However you decide to learn about quantum computing, though, welcome to the community! 💕
I’m really excited for what you bring to quantum computing.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/2019/09/08/this-is-not-a-qubit.html">
        This is Not a Qubit
      </a>
    </h1>

    <span class="post-date">08 Sep 2019</span>

    <h2 id="the-map-is-not-the-territory">The Map is Not The Territory</h2>

<p>There’s a classic observation in philosophy that “the map is not the territory.”
Though it sounds obvious enough to take entirely for granted, this observation reminds us that there is a difference between the world around us and how we choose to <em>represent</em> that world on a map.
Depending on what we want to use the map for, we abstract away many different properties of the real world, such as reducing the amount of detail that we include (we clearly can’t include every object in the real world in our maps).
We may even add things to our map that don’t actually exist in the world, but that we find useful at a social level, such as national borders.
In all cases, we make these choices so that our model of the world (a map) lets us predict what will happen when walk around the world.
We can use those predictions to trade off different possible routes, guess at what might be an interesting place to visit, and so forth.</p>

<p><img src="/assets/figures/this-is-not-a-qubit.png" /></p>

<p>The lesson learned from separating maps from the world becomes far less obvious, however, when we are working with realities and abstractions that are less familiar to us.
It’s quite easy, for instance, for both newcomers and experienced quantum physicists to accidentally conflate a register of qubits with the model we use to predict what that register will do.
In particular, if we want to simulate how a quantum program transforms data stored in a register of qubits, we can write down a <em>state vector</em> for that register, then use a simulator to propagate that state vector through the unitary matrices for each instruction in our program.</p>

<p>As an example, we can use tools like Q# and the Quantum Development Kit to understand how a quantum program can cause two qubits in a quantum register to become entangled.
Using IQ# with Jupyter Notebook, we might something like the following (<a href="https://mybinder.org/v2/gist/cgranade/df78c32014986d77b054abf33c45b9d6/master">run online</a>):</p>

<pre><code class="language-Q#">In [1]: open Microsoft.Quantum.Diagnostics;
...     open Microsoft.Quantum.Measurement;
...     
...     operation DemonstrateEntanglement() : (Result, Result) {
...         using ((left, right) = (Qubit(), Qubit())) {
...             H(left);
...             CNOT(left, right);
...             
...             DumpMachine();
...             
...             return (MResetZ(left), MResetZ(right));
...         }
...     }
Out[1]: DemonstrateEntanglement
</code></pre>

<p>Here, we’ve defined a new operation that asks for two qubits, then runs the <a href="https://docs.microsoft.com/qsharp/api/qsharp/microsoft.quantum.intrinsic.h"><code class="language-plaintext highlighter-rouge">H</code></a> and <a href="https://docs.microsoft.com/qsharp/api/qsharp/microsoft.quantum.intrinsic.cnot"><code class="language-plaintext highlighter-rouge">CNOT</code></a> instructions on those qubits.
The call to <a href="https://docs.microsoft.com/qsharp/api/qsharp/microsoft.quantum.diagnostics.dumpmachine"><code class="language-plaintext highlighter-rouge">DumpMachine</code></a> asks the simulator to tell us what information it uses internally to predict what those instructions do, so that when we do the measurements at the end of the program, the simulator knows what it should return.
Looking at the output of this dump, we see that the simulator represents <code class="language-plaintext highlighter-rouge">left</code> and <code class="language-plaintext highlighter-rouge">right</code> by the state $\left(\ket{00} + \ket{11}\right) / \sqrt{2}$:</p>

<pre><code class="language-Q#">In [2]: %simulate DemonstrateEntanglement
# wave function for qubits with ids (least to most significant): 0;1
∣0❭:	 0.707107 +  0.000000 i	 == 	***********
    [ 0.500000 ]     --- [  0.00000 rad ]
∣1❭:	 0.000000 +  0.000000 i	 == 	           
    [ 0.000000 ]                   
∣2❭:	 0.000000 +  0.000000 i	 == 	           
    [ 0.000000 ]                   
∣3❭:	 0.707107 +  0.000000 i	 == 	***********
    [ 0.500000 ]     --- [  0.00000 rad ]
Out[2]: (One, One)
</code></pre>

<p>It might be then tempting to conclude that <code class="language-plaintext highlighter-rouge">left</code> and <code class="language-plaintext highlighter-rouge">right</code> <em>are</em> the state $\left(\ket{00} + \ket{11}\right) / \sqrt{2}$, but this runs counter to what we learned from the example of separating maps of the world from the world itself.
To resolve this, it helps to think a bit more about what a quantum state is in the context of a quantum program.
For starters, if I give you a copy of the state of a quantum register at any point in a quantum program, you can predict what the rest of that quantum program will do.
Implicit in the word “copy,” however, is that the state of a quantum register is a <em>classical</em> description of that register.
After all, you can’t copy a register of qubits, so the fact that we <strong>can</strong> copy the state is a dead giveaway that state vectors are a kind of classical model.
That classical model is a pretty useful one, to be fair; it not only lets you simulate what a register of qubits will do, but also lets you prepare new qubits in the same way, using techniques like the Shende–Bullock–Markov algorithm (offered in Q# as the <a href="https://docs.microsoft.com/qsharp/api/qsharp/microsoft.quantum.preparation.preparearbitrarystate"><code class="language-plaintext highlighter-rouge">Microsoft.Quantum.Preparation.PrepareArbitraryState</code></a> operation).</p>

<p>Put differently, while the No-Cloning Theorem tells us that we can’t copy the data encoded by a quantum register into a second register, we can definitely copy the set of steps we used to do that encoding, then use that recipe to prepare a second register.
Perhaps instead of saying the map is not the territory, then, we should say that the cake is not the recipe!
While I can use a recipe to prepare a new cake, and to understand what should happen if I follow a particular set of steps, it’s difficult to eat an abstract concept like a recipe and definitely not very tasty.
It’s also pretty difficult to turn one cake into two, but not that hard to bake a second cake following the same recipe.</p>

<h2 id="the-cake-is-not-a-lie">The Cake is Not a Lie</h2>

<p>Thinking of a quantum state as a kind of recipe I can use to prepare qubits, then, what good is a quantum program?
To answer that, let’s look at one more example in Q#:</p>

<pre><code class="language-Q#">In [3]: open Microsoft.Quantum.Diagnostics;
...     open Microsoft.Quantum.Measurement;
...     open Microsoft.Quantum.Arrays;
...     
...     operation DemonstrateMultiqubitEntanglement() : Result[] {
...         using (register = Qubit[10]) {
...             H(Head(register));
...             ApplyToEach(CNOT(Head(register), _), Rest(register));
...             
...             DumpMachine();
...             
...             return ForEach(MResetZ, register);
...         }
...     }
</code></pre>

<p>If we were to run this one, the simulator would dump out a state with $2^{10} = 1,024$ amplitudes, but it’s much easier to read and understand what that program does by looking at the Q# source itself.
From that perspective, a quantum program can help us understand a computational task by compressing it down from a description purely in terms of state vectors, focusing back on what we actually want to achieve using a quantum device.
The simplest and by far the most effective way to both achieve this compression is to simply write down the instructions we need to send to a quantum device to prepare our qubits in a particular state.
Thus, instead of writing $\ket{+}$, for instance, we write down the program <code class="language-plaintext highlighter-rouge">H(q)</code>.
Instead of writing down $\ket{++\cdots+}$, we write down <code class="language-plaintext highlighter-rouge">ApplyToEach(H, qs)</code>.
Instead of writing down a state vector for each individual step in a phase estimation experiment, we write a program that calls <a href="https://docs.microsoft.com/qsharp/api/qsharp/microsoft.quantum.simulation.estimateenergy"><code class="language-plaintext highlighter-rouge">EstimateEnergy</code></a>.
This has the massive added advantage that we can <em>optimize</em> our quantum programs; that is, we can write down a sequence of instructions that utilizes what we know about the task we’re trying to achieve to use as few quantum instructions as possible.</p>

<p>Indeed, the cake–recipe distinction is especially important as we consider actual quantum devices.
In order to solve interesting computational problems using quantum computers, we want to be able to measure actual qubits, and get useful answers back.
At that scale, writing down and thinking only in terms of state vectors simply isn’t possible.
We need instead to focus on what we actually want to do with our qubits.
Once we do that, we’re in a much better spot to have our cake and eat it, too.</p>

<hr />

<p>If you liked this post, you’ll love <a href="https://www.manning.com/books/learn-quantum-computing-with-python-and-q-sharp?a_aid=learn-qc-granade&amp;a_bid=ee23f338"><em>Learn Quantum Computing with Python and Q#</em></a>, now in early access preview from Manning Publications.
Check it out!</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/2018/12/03/getting-posh-with-qsharp.html">
        Getting PoSh with Q#
      </a>
    </h1>

    <span class="post-date">03 Dec 2018</span>

    <p><em>This post is a part of the <a href="https://blogs.msdn.microsoft.com/visualstudio/2018/11/15/q-advent-calendar-2018/">Q# Advent Calendar</a>, and is made available under the <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0 license</a>. Full source code for this post is available <a href="https://gist.github.com/cgranade/ae96f866edae67c6550a93cf463a8f43">on GitHub</a>.</em></p>

<p>When we program a quantum computer, at the end of the day, we are interested in asking classical questions about classical data.
This is a large part of <a href="https://blogs.msdn.microsoft.com/visualstudio/2018/11/15/why-do-we-need-q/">why we designed the Q# language</a> to treat quantum computers as accelerators, similar to how one might use a graphics card or a field-programmable gate array (FPGA) to speed up the execution of classical algorithms.</p>

<p>One implication of this way of thinking about quantum programming, though, is that we need for our quantum programs to be able to integrate into classical data processing workflows.
Since the classical host programs for Q# are .NET programs, this means that we can use the power of the .NET Core platform to integrate with a wide range of different workflows.
For instance, the <a href="https://docs.microsoft.com/quantum/libraries/chemistry/">quantum chemistry library</a> that is provided with the Quantum Development Kit includes a <a href="https://github.com/Microsoft/Quantum/tree/release/v0.3.1810/Chemistry/GetGateCount">sample</a> that uses <a href="https://github.com/PowerShell/PowerShell">PowerShell Core</a> together with Q# to process cost estimates for chemistry simulations.
From there, cost estimation results can be exported to any of the formats supported by PowerShell Core, such as XML or JSON, or can be processed further using open-source PowerShell modules, such as <a href="https://github.com/dfinke/ImportExcel">ImportExcel</a>.</p>

<p>In this post, I’ll detail how the PowerShell Core integration in the quantum chemistry sample works as an example of how to integrate Q# with other parts of the .NET ecosystem.</p>

<h2 id="what-is-powershell-core">What is PowerShell Core?</h2>

<p>First off, then, what is PowerShell anyway?
Like bash, tcsh, xonsh, fish, and <a href="https://en.wikipedia.org/wiki/Category:Unix_shells">many other shells</a>, PowerShell provides a command-line interface for running programs on and managing your computer.
Like many shells, PowerShell allows you to <em>pipe</em> the output from one command to the next, making it easy to quickly build up complicated data-processing workflows in a compact manner.
Suppose, for instance, we want to find the number of lines of source code in all Q# files in a directory:</p>

<pre><code class="language-PowerShell">PS&gt; cd Quantum/
PS&gt; Get-ChildItem -Recurse *.qs | ForEach-Object { Get-Content $_ } | Measure-Object -Line

Lines Words Characters Property
----- ----- ---------- --------
 7823

</code></pre>

<p>Where PowerShell differs from most shells, however, is that the data sent between commands by piping isn’t text, but .NET objects.</p>

<pre><code class="language-PowerShell">PS&gt; $measurement = Get-ChildItem -Recurse *.qs | ForEach-Object { Get-Content $_ } | Measure-Object -Line;
PS&gt; $measurement.GetType()

IsPublic IsSerial Name                                     BaseType
-------- -------- ----                                     --------
True     False    TextMeasureInfo                          Microsoft.PowerShell.Commands.MeasureInfo

</code></pre>

<p>This means that we can not only call methods on PowerShell variables, but can access strongly-typed properties of variables.</p>

<pre><code class="language-PowerShell">PS&gt; $measurement.Lines.GetType()

IsPublic IsSerial Name                                     BaseType
-------- -------- ----                                     --------
True     True     Int32                                    System.ValueType

</code></pre>

<p>This in turn makes it easy to convert between different representations of our data, such as exporting to JSON or XML.</p>

<pre><code class="language-PowerShell">PS&gt; $measurement | ConvertTo-Json
{
  "Lines": 7823,
  "Words": null,
  "Characters": null,
  "Property": null
}
PS&gt; $measurement | ConvertTo-Xml -As String
&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;Objects&gt;
  &lt;Object Type="Microsoft.PowerShell.Commands.TextMeasureInfo"&gt;
    &lt;Property Name="Lines" Type="System.Int32"&gt;7823&lt;/Property&gt;
    &lt;Property Name="Words" Type="System.Nullable`1[[System.Int32, System.Private.CoreLib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]]" /&gt;
    &lt;Property Name="Characters" Type="System.Nullable`1[[System.Int32, System.Private.CoreLib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e]]" /&gt;
    &lt;Property Name="Property" Type="System.String" /&gt;
  &lt;/Object&gt;
&lt;/Objects&gt;
</code></pre>

<p>Historically, PowerShell was released as <em>Windows PowerShell</em>, and was based on the .NET Framework.
Two and a half years ago, PowerShell was ported to .NET Core and made available cross-platform as <em>PowerShell Core</em>.</p>

<p>PowerShell Core is now openly developed and maintained on GitHub at the <a href="https://github.com/PowerShell/PowerShell">PowerShell/PowerShell</a> repository.
If you haven’t installed PowerShell Core already, the PowerShell team provides <a href="https://github.com/PowerShell/PowerShell#get-powershell">installers for Windows, many Linux distributions, and macOS</a>.
If you are currently using PowerShell on Windows, but aren’t sure if you’re using Windows PowerShell or PowerShell Core, you can check your current edition by looking at the <code class="language-plaintext highlighter-rouge">$PSVersionTable</code> automatic variable:</p>

<pre><code class="language-PowerShell">PS&gt; $PSVersionTable.PSEdition
</code></pre>

<p>This will output <code class="language-plaintext highlighter-rouge">Desktop</code> for Windows PowerShell, and will output <code class="language-plaintext highlighter-rouge">Core</code> for PowerShell Core.</p>

<h2 id="writing-powershell-commands-in-c">Writing PowerShell Commands in C#</h2>

<p>We can add new functionality to PowerShell by writing small commands, called <em>cmdlets</em>, as .NET classes.
Let’s see how this works by making a new C# class that rolls dice for us.
To get started, we need to make a new C# library using the .NET Core SDK:</p>

<pre><code class="language-PowerShell">PS&gt; dotnet new classlib -lang C# -o posh-die
# The automatic variable $$ always resolves to the last argument of the previous command.
# In this case, we can use it to quickly jump to the "posh-die" directory.
PS&gt; cd $$
</code></pre>

<p>This will make a new directory with a C# project file and a single C# source file, <code class="language-plaintext highlighter-rouge">Class1.cs</code>, that we can edit:</p>

<pre><code class="language-PowerShell"># gci is an alias for Get-ChildItem, which can be used in the same way as
# ls or dir, both of which are also aliases for Get-ChildItem.
PS&gt; gci

    Directory: C:\Users\cgranade\Source\Repos\QsharpBlog\2018\December\src\posh-die

Mode                LastWriteTime         Length Name
----                -------------         ------ ----
d-----       11/27/2018   1:25 PM                obj
-a----       11/27/2018   1:25 PM             85 Class1.cs
-a----       11/27/2018   1:25 PM            145 posh-die.csproj

</code></pre>

<p>To make this a PowerShell-enabled library, we need to add the right NuGet package:</p>

<pre><code class="language-PowerShell">PS&gt; dotnet add package PowerShellStandard.Library
</code></pre>

<p>This will make the <code class="language-plaintext highlighter-rouge">System.Management.Automation</code> namespace available, which has everything we need to write our own cmdlets.
Go on and add the following to <code class="language-plaintext highlighter-rouge">Class1.cs</code>:</p>

<pre><code class="language-C#">using System;
using System.Linq;

// This namespace provides the API that we need to implement
// to interact with PowerShell.
using System.Management.Automation;

namespace Quantum.Advent.PoSh
{
    // Each cmdlet is a class that inherits from Cmdlet, and is given
    // a name with the CmdletAttribute attribute.
    // Here, for instance, we define a new class that is exposed to
    // PowerShell as the Get-DieRoll cmdlet.
    [Cmdlet(VerbsCommon.Get, "DieRoll")]
    public class GetDieRoll : Cmdlet
    {

        // Our cmdlet class can have whatever private member variables,
        // just as any other C# class.
        private Random rng = new Random();

        // We can expose properties as command-line parameters using
        // ParameterAttribute. 
        // For instance, this property is exposed as the -NSides command-
        // line parameter, and allows the user to select what kind of die
        // they want to roll.
        [Parameter]
        public int NSides { get; set; } = 6;

        [Parameter]
        public int NRolls { get; set; } = 1;

        // The main logic to any cmdlet is implemented in the ProcessRecord
        // method, which is called whenever the cmdlet receives new data from
        // the pipeline.
        protected override void ProcessRecord()
        {
            foreach (var idxRoll in Enumerable.Range(0, NRolls))
            {
                // The WriteObject method lets us send new data out to the
                // pipeline. If there's no other commands to receive that data,
                // then it is printed out to the console.
                WriteObject(rng.Next(1, NSides + 1));
            }
        }

    }
}
</code></pre>

<p>We can then build our new cmdlet like any other .NET Core project:</p>

<pre><code class="language-PowerShell">PS&gt; dotnet build
Microsoft (R) Build Engine version 15.5.179.9764 for .NET Core
Copyright (C) Microsoft Corporation. All rights reserved.

  Restore completed in 15.79 ms for C:\Users\cgranade\Source\Repos\QsharpBlog\2018\December\src\posh-die\posh-die.csproj.
  posh-die -&gt; C:\Users\cgranade\Source\Repos\QsharpBlog\2018\December\src\posh-die\bin\Debug\netstandard2.0\posh-die.dll

Build succeeded.
    0 Warning(s)
    0 Error(s)
</code></pre>

<p>When we call <code class="language-plaintext highlighter-rouge">dotnet build</code>, the .NET Core SDK places a new assembly in <code class="language-plaintext highlighter-rouge">bin/Debug/netstandard2.0</code> that we can then import into PowerShell:</p>

<pre><code class="language-PowerShell">PS&gt; Import-Module bin/Debug/netstandard2.0/posh-die.dll
PS&gt; Get-DieRoll -NSides 4
2
</code></pre>

<p>Since this is a PowerShell cmdlet, we can pipe its output to any other PowerShell cmdlet.
For instance, we can check that the die is fair using <code class="language-plaintext highlighter-rouge">Measure-Object</code>:</p>

<pre><code class="language-PowerShell">PS&gt; Get-DieRoll -NSides 6 -NRolls 1000 | Measure-Object -Average -Minimum -Maximum | ConvertTo-Json
{
  "Count": 1000,
  "Average": 3.402,
  "Sum": null,
  "Maximum": 6.0,
  "Minimum": 1.0,
  "Property": null
}
</code></pre>

<h2 id="calling-into-the-quantum-development-kit-from-powershell">Calling into the Quantum Development Kit from PowerShell</h2>

<p>Quantum coins are clearly better than classical dice, so let’s add a new cmdlet that exposes a quantum random number generator (QRNG) instead.
We can start by adding the Quantum Development Kit packages to our project:</p>

<pre><code class="language-PowerShell">PS&gt; dotnet add package Microsoft.Quantum.Development.Kit --version 0.3.1811.1501-preview
PS&gt; dotnet add package Microsoft.Quantum.Canon --version 0.3.1811.1501-preview
</code></pre>

<p>We can then add Q# sources to our project and use them from C#.
Let’s go on and add a simple QRNG to the project by making a new source file called <code class="language-plaintext highlighter-rouge">Qrng.qs</code>:</p>

<pre><code class="language-Q#">namespace Quantum.Advent.PoSh {
    // The MResetX operation is provided by the canon, so we open that here.
    open Microsoft.Quantum.Canon;

    /// # Summary
    /// Implements a quantum random number generator (QRNG) by preparing a qubit
    /// in the |0⟩ state and then measuring it in the 𝑋 basis.
    ///
    /// # Output
    /// Either `0` or `1` with equal probability.
    operation NextRandomBit() : Int {
        mutable result = 1;
        using (qubit = Qubit()) {
            // We use the ternary operator (?|) to turn the Result from
            // MResetX into an Int to match how the C# RNG works.
            set result = MResetX(qubit) == One ? 1 | 0;
        }
        return result;
    }
}
</code></pre>

<p>We can then call this operation from a new cmdlet.
Add the following new class to <code class="language-plaintext highlighter-rouge">Class1.cs</code>, along with a new <code class="language-plaintext highlighter-rouge">using</code> declaration for <code class="language-plaintext highlighter-rouge">Microsoft.Quantum.Simulation.Simulators</code>:</p>

<pre><code class="language-C#">[Cmdlet(VerbsCommon.Get, "CoinFlip")]
public class GetCoinFlip : Cmdlet
{

    [Parameter]
    public int NFlips { get; set; } = 1;

    protected override void ProcessRecord()
    {
        // This time we make a new target machine that we can use to run the
        // QRNG.
        using (var sim = new QuantumSimulator())
        {
            // The foreach loop is the same as before, except that we call into
            // Q# in each iteration instead of calling methods of a Random
            // instance.
            foreach (var idxFlip in Enumerable.Range(0, NFlips))
            {
                WriteObject(NextRandomBit.Run(sim).Result);
            }
        }
    }
}
</code></pre>

<p>Before proceeding, let’s make sure to unload the previous version of our <code class="language-plaintext highlighter-rouge">posh-die</code> assembly:</p>

<pre><code class="language-PowerShell">PS&gt; Remove-Module posh-die
</code></pre>

<p>This will make sure that we can load the new version, and that your PowerShell session hasn’t locked the assembly file on disk.
That frees us up to rebuild the C# project for our PowerShell module, along with the new Q# code that we added above:</p>

<pre><code class="language-PowerShell">PS&gt; dotnet build
Microsoft (R) Build Engine version 15.5.179.9764 for .NET Core
Copyright (C) Microsoft Corporation. All rights reserved.

  Restore completed in 22.01 ms for C:\Users\cgranade\Source\Repos\QsharpBlog\2018\December\src\posh-die\posh-die.csproj.
  posh-die -&gt; C:\Users\cgranade\Source\Repos\QsharpBlog\2018\December\src\posh-die\bin\Debug\netstandard2.0\posh-die.dll

Build succeeded.
    0 Warning(s)
    0 Error(s)

Time Elapsed 00:00:01.20
</code></pre>

<p>When you try to import this module, however, you’ll get an error:</p>

<pre><code class="language-PowerShell"># ipmo is an alias for Import-Module.
PS&gt; ipmo .\bin\Debug\netstandard2.0\posh-die.dll
ipmo : Could not load file or assembly 'Microsoft.Quantum.Simulation.Core, Version=0.3.1811.1501, Culture=neutral, PublicKeyToken=40866b40fd95c7f5'. The system cannot find the file specified.
At line:1 char:1
+ ipmo .\bin\Debug\netstandard2.0\posh-die.dll
+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ CategoryInfo          : NotSpecified: (:) [Import-Module], FileNotFoundException
+ FullyQualifiedErrorId : System.IO.FileNotFoundException,Microsoft.PowerShell.Commands.ImportModuleCommand
</code></pre>

<p>What’s going on here?
The problem is that PowerShell couldn’t find the DLLs that make up the Quantum Development Kit.
Before, our project didn’t depend on anything else, but now we need to take one extra step of <em>publishing</em> after we build in order to put all the DLLs we need into the right place.
The .NET Core SDK makes this easy with the <code class="language-plaintext highlighter-rouge">dotnet publish</code> command.
Run the following, making sure to change <code class="language-plaintext highlighter-rouge">win10-x64</code> to <code class="language-plaintext highlighter-rouge">linux-x64</code> or <code class="language-plaintext highlighter-rouge">osx-x64</code> as appropriate (for a full list of runtime IDs, see the <a href="https://docs.microsoft.com/en-us/dotnet/core/rid-catalog">.NET Core documentation</a>):</p>

<pre><code class="language-PowerShell">PS&gt; dotnet publish --self-contained -r win10-x64
</code></pre>

<p>We can then import the assembly as a PowerShell module the same way as before and run its cmdlets, just making sure to import the published assembly instead:</p>

<pre><code class="language-PowerShell">PS&gt; ipmo .\bin\Debug\netstandard2.0\win10-x64\publish\posh-die.dll
PS&gt; Get-CoinFlip -NFlips 10
Zero
One
One
Zero
Zero
One
Zero
Zero
Zero
One
PS&gt; Get-CoinFlip -NFlips 1000 | Measure-Object -Maximum -Minimum -Average


Count    : 1000
Average  : 0.51
Sum      :
Maximum  : 1
Minimum  : 0
Property :

</code></pre>

<p>There you go, that’s everything you need to get up and running using the Quantum Development Kit as a part of your PowerShell-based data processing workflows!</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/2017/05/08/software-for-reproducible-papers.html">
        Software Tools for Writing Reproducible Papers
      </a>
    </h1>

    <span class="post-date">08 May 2017</span>

    <h3 id="preamble">Preamble</h3>

<p>This post is a ♯longread primarily intended for graduate students and postdocs, but should hopefully be accessible more broadly.
Reading through the post should take about an hour, while following the instructions completely may take the better part of a day.</p>

<p>As an important caveat, much of what this post discusses is still experimental, such that you may run into minor issues in following the steps listed below.
I apologize if this happens, and thank you for your patience.</p>

<p>In any case, if you find this post useful, please cite it in papers that you write using these tools; doing so helps me out and makes it easier for me to write more such advice in the future.</p>

<p>Finally, we note that we have not covered several very important tools here, such as <a href="https://www.reprozip.org/">ReproZip</a>.
This post is already over 6,000 words long, so we didn’t attempt to run through all possible tools.
We encourage further exploration, rather than thinking of this post as definitive.</p>

<p>Thanks for reading! ♥</p>

<h2 id="introduction">Introduction</h2>

<p>In <a href="https://www.cgranade.com/blog/2017/03/31/what-we-encourage.html">my previous post</a>, I detailed some of the ways our software tools and social structures encourage some actions and discourage others.
Especially when it comes to tasks such as writing reproducible papers that both offer to significantly improve research culture, but are somewhat challening in their own right, it’s critical to ensure that we positively encourage doing things a bit better than we’ve done them before.
That said, though my previous post spilled quite a few pixels on the what and the why of such encouragements, and of what support we need for reproducible research practices, I said very little about <em>how</em> one could practically do better.</p>

<p>This post tries to improve on that by offering a concrete and specific workflow that makes it somewhat easier to write the best papers we can.
Importantly, in doing so, I will focus on a paper-writing process that I’ve developed for my own use and that works well for me— everyone approaches things differently, so you may disagree (perhaps even vehemently) with some of the choices I describe here.
Even if so, however, I hope that in providing a specific set of software tools that work well together to support reproducible research, I can at least move the conversation forward and make my little corner of academia ever so slightly better.</p>

<p>Having said what my goals are with this post, it’s worth taking a moment to consider what <em>technical</em> goals we should strive for in developing and configuring software tools for use in our research.
First and foremost, I have focused on tools that are <em>cross-platform</em>: it is not my place nor my desire to mandate what operating system any particular researcher should use.
Moreover, we often have to collaborate with people that make dramatically different choices about their software environments.
Thus, we must be careful what barriers to entry we establish when we use methodologies that do not port well to platforms other than our own.</p>

<p>Next, I have focused on tools which minimize the amount of closed-source software that is required to get research done.
The conflict between closed-source software and reproducibility is obvious nearly to the point of being self-evident.
Thus, without being purists about the issue, it is still useful to reduce our reliance on closed-source gatekeepers as much as is reasonable given other constraints.</p>

<p>The last and perhaps least obvious goal that I will adopt in this post is that each tool we develop or adopt here should be useful for more than a single purpose.
Installing software introduces a new cognative load in understanding how it operates, and adds to the general maintenance cost we pay in doing research.
While this can be mitigated in part with appropriate use of package management, we should also be careful that we justify each piece of our software infrastructure in terms of what benefits it provides to us.
In this post, that means specifically that we will choose things that solve more than just the immediate problem at hand, but that support our research efforts more generally.</p>

<p>Without further ado, then, the rest of this post steps through one particular software stack for reproducible research in a piece by piece fashion.
I have tried to keep this discussion detailed, but not esoteric, in the hopes of making an accessible description.
In particular, I have not focused at all on how to develop scientific software of how to write reproducible code, but rather how to integrate such code into a high-quality manuscript.
My advice is thus necessarily specific to what I know, quantum information, but should be readily adapted to other fields.</p>

<p>Following that, I’ll detail the following components of a software stack for writing reproducible research papers:</p>

<ul>
  <li>Command-line environment: PowerShell</li>
  <li>TeX / LaTeX distribution: TeX Live and MiKTeX</li>
  <li>Literate programming environment: Jupyter Notebook</li>
  <li>Text editor: Visual Studio Code</li>
  <li>LaTeX template: <code class="language-plaintext highlighter-rouge">{revtex4-1}</code>, <code class="language-plaintext highlighter-rouge">{quantumarticle}</code>, and <code class="language-plaintext highlighter-rouge">{revquantum}</code></li>
  <li>Project layout</li>
  <li>Version control: Git</li>
  <li>arXiv build management: PoShTeX</li>
</ul>

<h2 id="command-line">Command Line</h2>

<p>Command-line interfaces and scripting languages provide a very powerful paradigm for automating disparate software tools into a single coherent process.
For our purposes, we will need to automate running TeX, running literate scientific computing notebooks, and packaging the results for publication.
Since these different software tools were not explicitly designed to work together, it will be easiest for our purposes to use a command-line scripting language to manage the entire process.
There are many compelling options out there, including celebrated and versatile systems such as <a href="https://www.gnu.org/software/bash/"><code class="language-plaintext highlighter-rouge">bash</code></a>,  <a href="http://www.tcsh.org/Welcome"><code class="language-plaintext highlighter-rouge">tcsh</code></a>, and <a href="http://zsh.sourceforge.net/"><code class="language-plaintext highlighter-rouge">zsh</code></a>, as well as newer tools such as <a href="https://fishshell.com/"><code class="language-plaintext highlighter-rouge">fish</code></a> and <a href="http://xon.sh/"><code class="language-plaintext highlighter-rouge">xonsh</code></a>.
For this post, however, I will describe how to use Microsoft’s open-source PowerShell instead.</p>

<p>Microsoft offers PowerShell easy-to-install packages for Linux and macOS / OS X on at their <a href="https://github.com/PowerShell/PowerShell#get-powershell">GitHub repository</a>.
For most Windows users, we don’t need to install PowerShell, but we will need to install a package manager to help us install a couple things later.
If you don’t already have <a href="https://chocolatey.org/">Chocolatey</a>, go on and install it now, following <a href="https://chocolatey.org/install">their instructions</a>.</p>

<p>Similarly, we will use the package manager <a href="https://brew.sh">Homebrew</a> for macOS / OS X.
The quickest way to install it is to run the following command in <code class="language-plaintext highlighter-rouge">Terminal</code>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>/usr/bin/ruby <span class="nt">-e</span> <span class="s2">"</span><span class="si">$(</span>curl <span class="nt">-fsSL</span> https://raw.githubusercontent.com/Homebrew/install/master/install<span class="si">)</span><span class="s2">"</span>
</code></pre></div></div>
<p>Also, be sure to restart your <code class="language-plaintext highlighter-rouge">Terminal</code> window after the installation.
Then, we install PowerShell with the following two commands:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew tap caskroom/cask
<span class="nv">$ </span>brew cask <span class="nb">install </span>powershell
</code></pre></div></div>
<p>The first command installs the <a href="https://caskroom.github.io">Homebrew Cask</a> extension for programs distributed as binaries.</p>

<h3 id="aside-why-powershell">Aside: Why PowerShell?</h3>

<p>As a brief aside, why PowerShell?
One of the long-standing annoyances to getting anything working in a reliable and cross-platform manner is that Windows is just not like Linux or macOS / OS X.
My interest here is not in saying that Windows is either good or bad, but to solve the problem of how to get things working across that divide in a reliable way.
Certainly, scripting languages like <code class="language-plaintext highlighter-rouge">bash</code> have been ported to Windows and work well there, but they don’t tend to work in a way that plays well with native tools.
For instance, it is difficult to get Cygwin Bash to reliably interoperate with commonly-used TeX distributions such as MiKTeX.</p>

<p>Many of these challenges arise from that <code class="language-plaintext highlighter-rouge">bash</code> and other such tools work by manipulating <em>strings</em>, rather than providing a typed programming environment.
Thus, any cross-platform portability must eventually deal with annoyances such as <code class="language-plaintext highlighter-rouge">/</code> versus <code class="language-plaintext highlighter-rouge">\</code> in file name paths, while leaving slashes invariant in cases such as TeX source.</p>

<p>By contrast, PowerShell can be used as a command-line REPL (read-evaluate-print loop) interface to the more structrued .NET programming environment.
That way, OS-specific differences such as <code class="language-plaintext highlighter-rouge">/</code> versus <code class="language-plaintext highlighter-rouge">\</code> can be handled as an API, rather than relying on string parsing for everything.
Moreover, PowerShell comes pre-installed on most recent versions of Windows, making it easier to deal with the comaprative lack of package management on most Windows installations.
(PowerShell even addresses this by providing some very nice package management features, which we will use in later sections.)</p>

<p>Since PowerShell has recently been open-sourced, we can readily rely on it for our purposes here.</p>

<h2 id="tex">TeX</h2>

<p>For writing a reproducible scientific paper, there’s really no substitute still for TeX.
Thus, if you don’t have TeX installed already, let’s go on and install that now.</p>

<h3 id="linux-only-tex-live">(Linux only) TeX Live</h3>

<p>We can use Ubuntu’s package manager to easily install TeX Live:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>apt <span class="nb">install </span>texlive
</code></pre></div></div>
<p>The process will be slightly different on other variants of Linux.</p>

<h3 id="windows-only-miktex">(Windows only) MiKTeX</h3>

<p>Since we installed Chocolatey earlier, it’s quite straightforward to install MiKTeX.
From an Administrator session of PowerShell (right-click on PowerShell in the Start menu, and press <em>Run as administrator</em>), run the following command:</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">choco</span><span class="w"> </span><span class="nx">install</span><span class="w"> </span><span class="nx">miktex</span><span class="w">
</span></code></pre></div></div>

<h3 id="macos--os-x-only--mactex">(macOS / OS X only)  MacTeX</h3>

<p>Installing <a href="http://www.tug.org/mactex/">MacTeX</a> is similarly straightforward using Homebrew Cask (which we should have installed earlier):</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew cask <span class="nb">install </span>mactex
</code></pre></div></div>
<h2 id="jupyter">Jupyter</h2>

<p>Moving on, let’s take a few seconds to get Jupyter up and running.
Put succiently, Jupyter is a powerful infrastructure fo scientific programming in a variety of different languages.
Indeed, even the name points to the diversity of tools supported, as it originates from a portmanteau of Julia, Python and R.
Jupyter goes well beyond these three examples, though, and supports a language-agnostic interface for programming in JavaScript, F#, and even MATLAB.</p>

<p>Of particular interest to us is the Jupyter Notebook functionality, previously known as IPython Notebook.
This tool allows us to write <em>literate</em> documents that intersperse source code, explanations, mathematics, figures and plots.
As such, Jupyter Notebook is ideal for providing lucid and readable explanations of numerical and experimental results, providing a way to clearly explain a reproducible project.</p>

<p>Though Jupyter is a language-independent framework, the code infrastructure itself is written in Python.
Thus, the easiest way to get Jupyter in a cross-platform way is to install a distribution of Python, such as Anaconda, that incldues Jupyter as a package.
Since we want to focus in this post on how to write papers rather than on the programming aspects, we won’t go into detail at the moment on how to <em>use</em> Jupyter; below, we suggest some resources for getting started with Jupyter as a programming tool.
For now, we focus on getting Jupyter installed and running.</p>

<p>On Windows, we can again rely on Chocolatey:</p>
<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">choco</span><span class="w"> </span><span class="nx">install</span><span class="w"> </span><span class="nx">anaconda3</span><span class="w">
</span></code></pre></div></div>

<p>On Linux and macOS / OS X, the process is <a href="https://nbviewer.jupyter.org/github/QuinnPhys/PythonWorkshop-science/blob/master/lecture-0-scicomp-tools-part0.ipynb#Python-with-the-Anaconda-Distribution-(30-Minutes)">not much more complicated</a>.</p>

<p>To get started using Juyter Notebook, we suggest the following tutorial:</p>
<ul>
  <li><a href="https://nbviewer.jupyter.org/github/QuinnPhys/PythonWorkshop-science/blob/master/lecture-2-python-general.ipynb#Jupyter-Notebook-(30-Minutes)">EQuS Workshop on Python for Quantum Information Science: Lecture 2</a></li>
</ul>

<h2 id="editor">Editor</h2>

<p>In keeping with our goals in the introduction, to actually write TeX source code, we don’t want a tool that works <em>only</em> for TeX.
Rather, we want something general-purpose that is <em>also</em> useful for TeX.
By doing so, we avoid the all-too-familiar workflow of using a specialized editor for each different part of a scientific project.
This way, increased familiarity and proficiency with our software tools benefits us across the board.</p>

<p>With that in mind, we’ll follow the example of Visual Studio Code, an open-source and cross-platform text editing and development platform from Microsoft.
Notably, many other good examples exist, such as Atom; we focus on VS Code here as an example rather than as a recommendation over other tools.</p>

<p>With that aside, let’s start by installing.</p>

<p>If you’re running on Ubuntu or macOS / OS X, let’s download Visual Studio Code from the <a href="https://code.visualstudio.com/Download">VS Code website</a>.
Alternatively for macOS / OS X, you can use Homebrew Cask</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew cask <span class="nb">install </span>visual-studio-code
</code></pre></div></div>
<p>On Ubuntu, we only need to install VS Code manually the first time; after that, Code can be managed using Ubuntu Software Center in the same manner as built-in packages.
Meanwhile, the macOS / OS X version is installed by dragging the downloaded app into Applications.</p>

<p>Once again, Chocolatey comes to the rescue for Windows users:</p>
<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">choco</span><span class="w"> </span><span class="nx">install</span><span class="w"> </span><span class="nx">visualstudiocode</span><span class="w">
</span></code></pre></div></div>

<p>In any case, once we have VS Code installed, let’s install a few extensions that will make our lives much easier in the rest of this post.
Thankfully, this is quite straightforward due to the use of <em>extension packs</em>.
Roughly, an extension pack is a special kind of extension that does nothing on its own, but specifies a list of other extensions that should be installed.
I maintain a rudimentary example of such for use in scientific computing that includes some useful extensions for our purposes here.
To install it, press <strong>Ctrl+Shift+X</strong> (Windows and Linux) / <strong>⌘+Shift+X</strong> (macOS / OS X) to open the Extensions panel, and search for <code class="language-plaintext highlighter-rouge">cgranade.scicomp-extension-pack</code>.
Though the full functionality exposed by these extensions is beyond the scope of this post, we’ll explore some important parts as we discuss other parts of our software stack.</p>

<p>For the most part, the extensions installed by the Scientific Computing Extension Pack do not need any configuration.
The exception is that for MiKTeX on Windows, the LaTeX Workshop extension needs to be configured to run <code class="language-plaintext highlighter-rouge">texify</code> instead of its default build engine of <code class="language-plaintext highlighter-rouge">latexmk</code>.
To do so press <strong>Ctrl+Shift+P</strong> / <strong>⌘+Shift+P</strong> and type “Settings” until you are offered “Preferences: Open User Settings.”
Next, copy the following JavaScript Object Notation (JSON) code into your user settings:</p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">"latex-workshop.latex.toolchain"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
        </span><span class="nl">"command"</span><span class="p">:</span><span class="w"> </span><span class="s2">"texify"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"args"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
            </span><span class="s2">"--synctex"</span><span class="p">,</span><span class="w">
            </span><span class="s2">"--tex-option=</span><span class="se">\"</span><span class="s2">-interaction=nonstopmode</span><span class="se">\"</span><span class="s2">"</span><span class="p">,</span><span class="w">
            </span><span class="s2">"--tex-option=</span><span class="se">\"</span><span class="s2">-file-line-error</span><span class="se">\"</span><span class="s2">"</span><span class="p">,</span><span class="w">
            </span><span class="s2">"--pdf"</span><span class="p">,</span><span class="w">
            </span><span class="s2">"%DOC%.tex"</span><span class="w">
        </span><span class="p">]</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">]</span><span class="w">
</span></code></pre></div></div>
<p>Getting forward and inverse search with SyncTeX working on Windows also takes a slight bit more work, as is documented <a href="http://tex.stackexchange.com/questions/338078/how-to-get-synctex-for-windows-to-allow-atom-pdf-view-to-synch#comment877274_338117">on StackExchange</a>.</p>

<p>This demonstrates one of the really neat features of modern editing platforms, by the way.
Namely, it’s very easy to share human-readable configuration snippets with others, making it easier to build a common platform with collegues and collaborators.</p>

<h2 id="latex-template">LaTeX Template</h2>

<p>With the slight caveat that this section is the most specific to quantum information processing, we next turn our attention to the <em>raison d’être</em> for this whole endeavor: our LaTeX manuscript itself.
In doing so, we try to minimize the size of our initial template.
By minimizing the amount of boilerplate, we reduce the extent to which we introduce bugs in creating new manuscripts.
More importantly, though, keeping our template minimal reduces how much we have to understand in order to use and maintain it.</p>

<p>That said, we will generally have a lot of LaTeX code shared between projects.
To keep our manuscript templates minimal and free of boilerplate, then, we can rely on LaTeX’s <em>document class</em> and <em>package</em> functionality to abstract away this shared code.
For instance, the <a href="https://journals.aps.org/revtex"><code class="language-plaintext highlighter-rouge">{revtex4-1}</code></a> document class abstracts away much of the work involved in formatting a manuscript for physics papers, while the <a href="https://github.com/cgogolin/quantum-journal"><code class="language-plaintext highlighter-rouge">{quantumarticle}</code></a> class does similar for the new Quantum journal.
Similarly, my own <a href="https://github.com/cgranade/revquantum"><code class="language-plaintext highlighter-rouge">{revquantum}</code></a> package attempts to abstract away much of the LaTeX code that I carry from project to project.</p>

<p>Though <code class="language-plaintext highlighter-rouge">{revquantum}</code> can be downloaded from the Comprehensive TeX Archive Network (CTAN), it will be easier for us to use Git to download the latest version.
We’ll install Git a bit later on in the post, so we’ll focus on the template for now and will install the required LaTeX packages once we have Git at our disposal.</p>

<p>Following that strategy, we can now write a very minimal LaTeX template:</p>

<div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\documentclass</span><span class="na">[aps,pra,twocolumn,notitlepage,superscriptaddress]</span><span class="p">{</span>revtex4-1<span class="p">}</span>
<span class="k">\usepackage</span><span class="na">[pretty,strict]</span><span class="p">{</span>revquantum<span class="p">}</span>

<span class="k">\newcommand</span><span class="p">{</span><span class="k">\figurefolder</span><span class="p">}{</span>figures<span class="p">}</span>

<span class="nt">\begin{document}</span>

<span class="k">\title</span><span class="p">{</span>Example paper<span class="p">}</span>
<span class="k">\date</span><span class="p">{</span><span class="k">\today</span><span class="p">}</span>

<span class="k">\author</span><span class="p">{</span>Cassandra Granade<span class="p">}</span>
    <span class="k">\affilEQuSUSyd</span>
    <span class="k">\affilUSydPhys</span>

<span class="nt">\begin{abstract}</span>
    <span class="k">\TODO</span>
<span class="nt">\end{abstract}</span>

<span class="k">\maketitle</span>

<span class="k">\bibliography</span><span class="p">{</span>biblio<span class="p">}</span>

<span class="nt">\end{document}</span>
</code></pre></div></div>

<p>Note that this template strips down the preamble (that is, the part of the LaTeX document before <code class="language-plaintext highlighter-rouge">\begin{document}</code>) to just three lines:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">\documentclass[aps,pra,twocolumn,notitlepage,superscriptaddress]{revtex4-1}</code>:
Declares the document class to be <code class="language-plaintext highlighter-rouge">{revtex4-1}</code> and specifies some reasonable default options.
Note that if an option isn’t specified for the society, journal or font size, <code class="language-plaintext highlighter-rouge">{revtex4-1}</code> will raise warnings.
Thus, by specifying a few options, we reduce the number of spurious warnings that we have to sort through.</li>
  <li><code class="language-plaintext highlighter-rouge">\usepackage[pretty,strict]{revquantum}</code>:
Includes the <code class="language-plaintext highlighter-rouge">{revquantum}</code> package with modern typesetting options.
The <code class="language-plaintext highlighter-rouge">strict</code> option instructs <code class="language-plaintext highlighter-rouge">{revquantum}</code> to promote package incompatability warnings to errors, such that the manuscript will refuse to compile if there are issues with <code class="language-plaintext highlighter-rouge">{revtex4-1}</code> compatability.</li>
  <li><code class="language-plaintext highlighter-rouge">\newcommand{\figurefolder}{.}</code>:
We’ll see more about this in the rest of the post, but roughly this command lets us abstract away details of our project structure from our LaTeX source.
That in turn will make it much easier to rearrange the project folder as need be, as only minimal changes will be required in the LaTeX source itself.</li>
</ul>

<h2 id="project-layout">Project Layout</h2>

<p>Now that we have a reasonable template in place for our paper, let’s proceed to make and layout a folder for our project.
The project folder needs to have somewhere to store the TeX source we use in typesetting the paper, and will likely need somewhere to store figures as well.
Assuming we have either numerics or an experiment in our paper, we will also need somewhere to put our Jupyter Notebooks and any other source files that they rely upon.</p>

<p>Putting these needs together, my projects often wind up looking something like this:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">project/</code>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">tex/</code>
        <ul>
          <li><code class="language-plaintext highlighter-rouge">project.tex</code>:
Main TeX source file.</li>
          <li><code class="language-plaintext highlighter-rouge">project.bib</code>:
Bibliography for main TeX source.</li>
          <li><code class="language-plaintext highlighter-rouge">revquantum.sty</code>:
A copy of the <code class="language-plaintext highlighter-rouge">{revquantum}</code> package.
We will download and build <code class="language-plaintext highlighter-rouge">{revquantum}</code> later in this post.</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">fig/</code>
        <ul>
          <li><code class="language-plaintext highlighter-rouge">*.pdf</code>:
PDF-formatted figures for use in the main body.</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">src/</code>
        <ul>
          <li><code class="language-plaintext highlighter-rouge">project.ipynb</code>:
Main literate notebook for the project.</li>
          <li><code class="language-plaintext highlighter-rouge">*.py</code>:
One or two miscellaneous Python modules needed for the main notebook.</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">data/</code>:
Folder for experimental data generated by <code class="language-plaintext highlighter-rouge">src/project.ipynb</code>. <br />
<strong>NB:</strong> do <strong>not</strong> use NumPy’s <code class="language-plaintext highlighter-rouge">*.npz</code> format for uploading data to arXiv as ancillary material, as this is not supported by arXiv.
Consider using HDF5 or similar instead.
If your data set is moderately-sized (&gt; 6 MiB), then consider uploading to an external service such as <a href="https://figshare.com/">Figshare</a> instead of arXiv— this also makes it easier to use other data storage formats.</li>
      <li><code class="language-plaintext highlighter-rouge">.gitignore</code>:
A list of files, folders, and patterns to be excluded from version control.
Don’t worry about this for now, we’ll deal with it below.</li>
      <li><code class="language-plaintext highlighter-rouge">README.md</code>:
Brief instructions on how to use the ancillary files provided with the paper.</li>
      <li><code class="language-plaintext highlighter-rouge">environment.yml</code> or <code class="language-plaintext highlighter-rouge">requirements.txt</code>:
Software dependencies needed by the project.
How these files work is fairly specific to programming in Python, so we won’t go into the details here, but they make it easy for both collaborators and readers to quickly set up the software environment they need to run your code.
For more details, please see the documentation for <a href="https://pip.pypa.io/en/stable/"><code class="language-plaintext highlighter-rouge">pip</code></a> and <a href="https://conda.io/docs/using/envs.html"><code class="language-plaintext highlighter-rouge">conda env</code></a>.</li>
      <li><code class="language-plaintext highlighter-rouge">Export-ArXiv.ps1</code>:
Build manifest for exporting the paper to an arXiv-formatted ZIP archive.
Later in the post, we’ll detail what this file should contain and how to use it.
For now, just make a blank text file with this name.</li>
    </ul>
  </li>
</ul>

<p>As with everything else in this post, you may want to layout your project differently than I’ve suggested here.
For instance, we included a copy of <code class="language-plaintext highlighter-rouge">revquantum.sty</code> above, since that’s not part of the “standard” set of packages installed on arXiv; if you depend on any other custom packages or classes, those would also appear in your layout.
If you have more than one or two other source files in <code class="language-plaintext highlighter-rouge">src/</code>, you may also want to make a package and distribute it separately from your paper.
You may also have additional files that you need to include, such as <a href="https://instrumentkit.readthedocs.io/en/latest/apiref/config.html">instrument configuration files</a>.
It’s also common to have other folders like <code class="language-plaintext highlighter-rouge">notes/</code> to keep rough or unfinished derivations, or <code class="language-plaintext highlighter-rouge">refereeing/</code> to draft correspondance with referees and editors once you submit your paper.</p>

<p>What’s essential, though, is that no matter how you layout your project, you use the layout as consistantly as possible.
Doing so ensures that a file you need can always be found in the least surprising place, minimizing the amount of thought you have to spare on searching your folder structure.
Importantly, if this means you need to change your layout as your project itself changes, that is a fine and useful thing to do.
Your layout should, above all else, work for you and your collaborators with as little friction and additional thought as is reasonable.</p>

<h2 id="version-control">Version Control</h2>

<p>Once you’ve made a project folder, we need to be able to track how it changes over time and to share it with collaborators.
Though file-synchronization tools such as <a href="http://dropbox.com/">Dropbox</a>, <a href="https://www.google.com/drive/">Google Drive</a>, and <a href="https://onedrive.live.com/">OneDrive</a> are commonly used for this task, they introduce a lot of additional maintenance costs that we would like to avoid.
For instance, it’s very difficult to collaborate using such services— conflicting edits are normally applied with preference only to whichever edits happened last, making it easy to accidently lose important edits.
Similarly, it’s hard to look at a source file and understand <em>why</em> a particular set of changes was made, such that it’s again too easy to accidentally undo edits from collaborators.</p>

<p>In keeping with the goals laid out at the start of the post, then, we’ll adopt <em>distributed version control</em> as a tool to enable collaboration and version tracking.
In particular, we will use Git in no small part due to its popularity, such that we can build off a large set of community-developed tools and services.
Git is a very useful tool in general, such that we again avoid overly-specialized software infrastructure.</p>

<p>I won’t lie: there is a learning curve to Git, such that initially it will take substantially longer to do research backed by Git than by file-synchronization tools.
In fairly short order, however, learning Git pays for itself both by avoiding common pitfalls introduced by file-synchronization tools and by providing powerful automation for other tasks outside the synchronization model.
Both the learning curve and the power of Git stem from the same source, in that Git is extremely reticent to erase any set of changes, no matter how insignificant.
For instance, if two contradictory sets of changes are made to a file, Git will demand that you explicitly specify how to merge them, rather than automatically overwritting changes that may be significant.</p>

<p>We won’t cover how to use Git in this post, but rather will focus on how to install it and configure it for setting up a reproducible paper.
In lieu, we recommend the following tutorials:</p>

<ul>
  <li><a href="https://nbviewer.jupyter.org/github/QuinnPhys/PythonWorkshop-science/blob/master/lecture-1-scicomp-tools-part1.ipynb">EPQIS Workshop: Lecture 1</a></li>
  <li><a href="http://try.github.com/">GitHub: Try Git</a></li>
  <li><a href="http://swcarpentry.github.io/git-novice/">Software Carpentry: Version Control with Git</a></li>
  <li><a href="https://mozfellows-hack.github.io/friendly-github-intro/">Mozilla Science Lab: A Friendly GitHub Intro Workshop</a></li>
</ul>

<p>In following these tutorials, we recommend starting by using the command line as much as possible, as this helps build the volcabulary needed when working with graphical interfaces to Git.</p>

<p>In any case, let’s go on and install Git.
We will install Secure Shell (SSH) while we’re at it, since this is a very common and powerful way of interfacing with Git hosting providers such as <a href="https://github.com/">GitHub</a>, <a href="http://bitbucket.com/">Bitbucket</a>, and <a href="https://about.gitlab.com/">GitLab</a>.
Notably, SSH is also very useful for other research tasks such as managing cluster resources and running Jupyter Notebooks on remote servers, such that in installing SSH we get access to another general-purpose tool.</p>

<p>On Windows, run the following in an Administrator PowerShell session:</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">choco</span><span class="w"> </span><span class="nx">install</span><span class="w"> </span><span class="nx">git</span><span class="w"> </span><span class="nx">putty</span><span class="w"> </span><span class="nx">poshgit</span><span class="w">
</span></code></pre></div></div>
<p>If you haven’t already done so, you’ll need to set PuTTY to be the SSH implementation used by Git for Windows.
From within PowerShell, run the following:</p>
<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="p">[</span><span class="n">Environment</span><span class="p">]::</span><span class="nx">SetEnvironmentVariable</span><span class="p">(</span><span class="s2">"GIT_SSH"</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="n">Get-Command</span><span class="w"> </span><span class="nx">plink.exe</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Select-Object</span><span class="w"> </span><span class="nt">-ExpandProperty</span><span class="w"> </span><span class="nx">Definition</span><span class="p">),</span><span class="w"> </span><span class="s2">"User"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<p>If this doesn’t work, it’s likely because <code class="language-plaintext highlighter-rouge">Get-Command plink.exe</code> was unable to find the <code class="language-plaintext highlighter-rouge">plink.exe</code> command that comes with PuTTY.
This can happen, for instance, if the <code class="language-plaintext highlighter-rouge">$Env:PATH</code> environment variable was changed by <code class="language-plaintext highlighter-rouge">choco install</code> but not in your current PowerShell session.
The easiest way to fix this is to close and re-open your PowerShell session.</p>

<p>Notice that we’ve also installed <code class="language-plaintext highlighter-rouge">poshgit</code> (short for PowerShell Git) with this command, as that handles a lot of nice Git-related tasks within PowerShell.
To add posh-git to your prompt, please see the <a href="https://github.com/dahlbyk/posh-git/#using-posh-git">instructions provided with posh-git</a>.
One of the more useful effects of adding posh-git to your prompt is that posh-git will then look at your setting for <code class="language-plaintext highlighter-rouge">$Env:GIT_SSH</code> and automatically manage your PuTTY configuration for you.</p>

<p>On Ubuntu, run the following in your favorite shell:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>apt <span class="nb">install </span>ssh git
</code></pre></div></div>
<p>This may warn that some or all of the needed packages are already installed— if so, that’s fine.</p>

<p>On macOS / OS X, SSH is pre-installed by default. To install Git, run <code class="language-plaintext highlighter-rouge">git</code> at the terminal and follow the installation prompts. 
However, the versions of ssh and git distributed with macOS / OS X are often outdated.
Homebrew to the rescue:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install </span>ssh git
</code></pre></div></div>

<p>Note that posh-git also partially works on PowerShell for Linux and macOS / OS X, but does not yet properly handle setting command-line prompts.</p>

<p>Once everything is installed, simply run <code class="language-plaintext highlighter-rouge">git init</code> from within your project folder to turn your project into a Git repository.
Use <code class="language-plaintext highlighter-rouge">git add</code> and <code class="language-plaintext highlighter-rouge">git commit</code>, either at the command line or using your editor’s Git support, to add your initial project folder to your local repository.</p>

<p>The next steps from here depend somewhat on which Git hosting provider you wish to use, but proceed roughly in four steps:</p>

<ul>
  <li>Create a new repository on your hosting provider.</li>
  <li>Configure your SSH private and public keys for use with your hosting provider.</li>
  <li>Add your hosting provider as a <code class="language-plaintext highlighter-rouge">git remote</code> to your local project.</li>
  <li>Use <code class="language-plaintext highlighter-rouge">git push</code> to upload your local repository to the new remote.</li>
</ul>

<p>Since the details depend on your choice of provider, we won’t detail them here, though some of the tutorials provided above may be useful.
Rather, we suggest following documentation for the hosting provider of your choice in order to get up and running.</p>

<p>In any case, as promised above, we can now use Git to download and install the LaTeX packages that we require.
To get <code class="language-plaintext highlighter-rouge">{revquantum}</code>, we’ll run the included PowerShell installer.
Note that, due to a bug that installer (currently being fixed), this will fail unless you already have <a href="johnmacfarlane.net/pandoc/">Pandoc</a> installed.
Thus, we’ll go on and work around that bug for now by installing Pandoc (besides, it’s useful in writing responses to referees, as I’ll discuss in a future post):</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># macOS</span>
<span class="nv">$ </span>brew <span class="nb">install </span>pandoc
<span class="c"># Ubuntu</span>
<span class="nv">$ </span><span class="nb">sudo </span>apt <span class="nb">install </span>pandoc
<span class="c"># Windows</span>
PS&gt; choco <span class="nb">install </span>pandoc
</code></pre></div></div>
<p>I sincerely apologize for this bug, and will have it fixed soon.
In any case, and having apologized for introducing additional requirements, let’s go on and install the packages themselves:</p>
<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">git</span><span class="w"> </span><span class="nx">clone</span><span class="w"> </span><span class="nx">https://github.com/cgranade/revquantum.git</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">cd</span><span class="w"> </span><span class="nx">revquantum</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="c"># Only run the following on Windows, as Unblock-File isn't needed</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="c"># on Linux and macOS / OS X.</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Unblock-File</span><span class="w"> </span><span class="nx">Install.ps1</span><span class="w"> </span><span class="c"># Marks that the installer is safe to run.</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="o">.</span><span class="nx">/Install.ps1</span><span class="w">
</span></code></pre></div></div>

<p>Installing the <code class="language-plaintext highlighter-rouge">{quantumarticle}</code> document class proceeds similarly:</p>
<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">git</span><span class="w"> </span><span class="nx">clone</span><span class="w"> </span><span class="nx">https://github.com/cgogolin/quantum-journal.git</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">cd</span><span class="w"> </span><span class="nx">quantum-journal</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="c"># Only run the following on Windows, as Unblock-File isn't needed</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="c"># on Linux and macOS / OS X.</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Unblock-File</span><span class="w"> </span><span class="nx">install.ps1</span><span class="w"> </span><span class="c"># NB: "install" is spelled with a lower-case i here!</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="o">.</span><span class="nx">/install.ps1</span><span class="w">
</span></code></pre></div></div>

<p>Note that in the above, we used HTTPS URLs instead of the typical SSH.
This allows us to download from GitHub without having to set up our public keys first.
Since at the moment, we’re only interested in downloading copies of <code class="language-plaintext highlighter-rouge">{revquantum}</code> and <code class="language-plaintext highlighter-rouge">{quantumarticle}</code>, rather than actively developing them, HTTPS URLs work fine.
That said, for your own projects or for contributing changes to other projects, we recommend taking the time to set up SSH keys and using that instead.</p>

<h3 id="aside-working-with-git-in-vs-code">Aside: Working with Git in VS Code</h3>

<p>As another brief aside, it’s worth taking a moment to see how Git can help enable collaborative and reproducible work.
The Scientific Computation Extension Pack for VS Code that we installed earlier includes the amazingly useful <a href="https://marketplace.visualstudio.com/items?itemName=donjayamanne.git-extension-pack">Git Extension Pack</a> maintained by Don Jayamanne, which in turn augments the already powerful Git tools built into Code.</p>

<p>For instance, the <a href="https://marketplace.visualstudio.com/items?itemName=donjayamanne.githistory">Git History</a> extension provides us with a nice visualization of the history of a Git repository.
Press <strong>Ctrl/⌘+Shift+P</strong>, then type “log” until you are offered “Git: View History (git log).”
Using this on the <a href="http://qinfer.org/">QInfer</a> repository as an example, I am presented with a visual history of my local repository:</p>

<p><img src="/assets/figures/qinfer-git-log-vscode.png" /></p>

<p>Clicking on any entry in the history visualization presents me with a summary of the changes introduced by that commit, and allows us to quickly make comparisons.
This is invaluable in answering that age old question, “what the heck did my collaborators change in the draft this time?”</p>

<p>Somewhat related is the <a href="https://marketplace.visualstudio.com/items?itemName=eamodio.gitlens">GitLens</a> extension, which provides inline annotations about the history of a file while you edit it.
By default, these annotations are only visible at the top of a section or other major division in a source file, keeping them unobtrusive during normal editing.
If you temporarily want more information, however, press <strong>Alt+B</strong> to view “blame” information about a file.
This will annotate each line with a short description of who edited it last, when they did so, and why.</p>

<p><img src="/assets/figures/qinfer-git-blame-vscode.png" /></p>

<p>The last VS Code extension we’ll consider for now is the <a href="https://marketplace.visualstudio.com/items?itemName=alefragnani.project-manager">Project Manager</a> extension, which makes it easy to quickly switch between Git repositories and manage multiple research projects.
To use it, we need to do a little bit of configuration first, and tell the extension where to find our projects.
Add the following to your user settings, changing paths as appropriate to point to where you keep your research repositories:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">"projectManager.git.baseFolders"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="s2">"C:</span><span class="se">\\</span><span class="s2">users</span><span class="se">\\</span><span class="s2">cgranade</span><span class="se">\\</span><span class="s2">academics</span><span class="se">\\</span><span class="s2">research"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"C:</span><span class="se">\\</span><span class="s2">users</span><span class="se">\\</span><span class="s2">cgranade</span><span class="se">\\</span><span class="s2">software-projects"</span><span class="w">
</span><span class="p">]</span><span class="w">
</span></code></pre></div></div>

<p>Note that on Windows, you need to use <code class="language-plaintext highlighter-rouge">\\</code> instead of <code class="language-plaintext highlighter-rouge">\</code>, since <code class="language-plaintext highlighter-rouge">\</code> is an <em>escape character</em>.
That is, <code class="language-plaintext highlighter-rouge">\\</code> indicates that the next character is special, such that you need two backslashes to type the Windows path separator.</p>

<p>Once configured, press <strong>Alt+Shift+P</strong> to bring up a list of projects.
If you don’t see anything at first, that’s normal; it can take a few moments for Project Manager to discover all of your repositories.</p>

<h3 id="aside-viewing-tex-differences-as-pdfs-linux-and-macos--os-x-only">Aside: Viewing TeX Differences as PDFs (Linux and macOS / OS X only)</h3>

<p>One very nice advantage of using Git to manage TeX projects is that we can use Git together with the excellent <code class="language-plaintext highlighter-rouge">latexdiff</code> tool to make PDFs annotated with changes between different versions of a project.
Sadly, though <code class="language-plaintext highlighter-rouge">latexdiff</code> does run on Windows, it’s quite finnicky to use with MiKTeX.
(Personally, I tend to find it easier to use the Linux instructions on Windows Subsystem for Linux, then run <code class="language-plaintext highlighter-rouge">latexdiff</code> from within Bash on Ubuntu on Windows.)</p>

<p>In any case, we will need two different programs to get up and running with PDF-rendered diffs.
Sadly, both of these are somewhat more specialized than the other tools we’ve looked at, violating the goal that everything we install should also be of generic use.
For that reason, and because of the Windows compatability issues noted above, we won’t depend on PDF-rendered diffs anywhere else in this post, and mention it here as a very nice aside.</p>

<p>That said, we will need by <code class="language-plaintext highlighter-rouge">latexdiff</code> itself, which compares changes between two different TeX source versions, and <code class="language-plaintext highlighter-rouge">rcs-latexdiff</code>, which interfaces between <code class="language-plaintext highlighter-rouge">latexdiff</code> and Git. 
To install <code class="language-plaintext highlighter-rouge">latexdiff</code> on Ubuntu, we can again rely on <code class="language-plaintext highlighter-rouge">apt</code>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>apt <span class="nb">install </span>latexdiff
</code></pre></div></div>
<p>For macOS / OS X, the easiest way to install latexdiff is to use the package manager of MacTeX.
Either use <code class="language-plaintext highlighter-rouge">Tex Live Utiliy</code>, a GUI program distributed with MacTeX or run the following command in a shell</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>tlmgr update <span class="nt">--self</span>
<span class="nv">$ </span><span class="nb">sudo </span>tlmgr <span class="nb">install </span>latexdiff
</code></pre></div></div>

<p>For <code class="language-plaintext highlighter-rouge">rcs-latexdiff</code>, I recommend the <a href="https://github.com/ihincks/rcs-latexdiff/"><em>fork</em> maintained by Ian Hincks</a>.
We can use the Python-specific package manager <code class="language-plaintext highlighter-rouge">pip</code> to automatically download Ian’s Git repository for <code class="language-plaintext highlighter-rouge">rcs-latexdiff</code> and run its installer:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>pip <span class="nb">install </span>git+https://github.com/ihincks/rcs-latexdiff.git
</code></pre></div></div>

<p>Once you have <code class="language-plaintext highlighter-rouge">latexdif</code> and <code class="language-plaintext highlighter-rouge">rcs-latexdiff</code> installed, we can make very professional PDF renderings by calling <code class="language-plaintext highlighter-rouge">rcs-latexdiff</code> on different Git commits.
For instance, if you have a Git <a href="https://git-scm.com/book/en/v2/Git-Basics-Tagging"><em>tag</em></a> for version 1 of an arXiv submission, and want to prepare a PDF of differences to send to editors when resubmitting, the following command often works:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>rcs-latexdiff project_name.tex arXiv_v1 HEAD
</code></pre></div></div>
<p>Sometimes, you may have to specify options such as <code class="language-plaintext highlighter-rouge">--exclude-section-titles</code> due to compatability with the <code class="language-plaintext highlighter-rouge">\section</code> command in <code class="language-plaintext highlighter-rouge">{revtex4-1}</code> and <code class="language-plaintext highlighter-rouge">{quantumarticle}</code>.</p>

<h2 id="arxiv-build-management">arXiv Build Management</h2>

<p>Ideally, you’ll upload your reproducible research paper to the arXiv once your project is at a point where you want to share it with the world.
Doing so manually is, in a word, painful.
In part, this pain originates from that arXiv uses a single automated process to prepare every manuscript submitted, such that arXiv must do something sensible for everyone.
This translates in practice to that we need to ensure that our project folder matches the expectations encoded in their TeX processor, AutoTeX.
These expectations work well for preparing manuscripts on arXiv, but are not quite what we want when we are writing a paper, so we have to contend with these conventions in uploading.</p>

<p>For instance, arXiv expects a single TeX file at the root directory of the uploaded project, and expects that any ancillary material (source code, small data sets, videos, etc.) are in a subfolder called <code class="language-plaintext highlighter-rouge">anc/</code>.
Perhaps most difficult to contend with, though, is that arXiv currently only supports subfolders in a project if that project is uploaded as a ZIP file.
This implies that if we want to upload even once ancillary file, which we certiantly will want to do for a reproducible paper, then we <strong>must</strong> upload our project as a ZIP file.
Preparing this ZIP file is in principle easy, but if we do so manually, it’s all too easy to make mistakes.</p>

<p>To rectify this and to allow us to use our own project folder layouts, I’ve written a set of commands for PowerShell collectively called PoShTeX to manage building arXiv ZIP archives.
From our perspective in writing a reproducible paper, we can rely on PowerShell’s built-in package management tools to automatically find and install PoShTeX if needed, such that our entire arXiv build process reduces to writing a single short <em>manifest file</em> then running it as a PowerShell command.</p>

<p>Let’s look at an example manifest.
This particular example comes from an ongoing research project with <a href="http://www.sckaiser.com">Sarah Kaiser</a> and <a href="https://csferrie.com/">Chris Ferrie</a>.</p>
<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#region Bootstrap PoShTeX</span><span class="w">
</span><span class="nv">$modules</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Get-Module</span><span class="w"> </span><span class="nt">-ListAvailable</span><span class="w"> </span><span class="nt">-Name</span><span class="w"> </span><span class="nx">posh-tex</span><span class="p">;</span><span class="w">
</span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="nv">$modules</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="n">Install-Module</span><span class="w"> </span><span class="nx">posh-tex</span><span class="w"> </span><span class="nt">-Scope</span><span class="w"> </span><span class="nx">CurrentUser</span><span class="p">}</span><span class="w">
</span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="p">(</span><span class="nv">$modules</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nf">?</span><span class="w"> </span><span class="p">{</span><span class="bp">$_</span><span class="o">.</span><span class="nf">Version</span><span class="w"> </span><span class="o">-ge</span><span class="w"> </span><span class="s2">"0.1.5"</span><span class="p">}))</span><span class="w"> </span><span class="p">{</span><span class="n">Update-Module</span><span class="w"> </span><span class="nx">posh-tex</span><span class="p">}</span><span class="w">
</span><span class="n">Import-Module</span><span class="w"> </span><span class="nx">posh-tex</span><span class="w"> </span><span class="nt">-Version</span><span class="w"> </span><span class="s2">"0.1.5"</span><span class="w">
</span><span class="c">#endregion</span><span class="w">

</span><span class="n">Export-ArXivArchive</span><span class="w"> </span><span class="p">@{</span><span class="w">
    </span><span class="nx">ProjectName</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"sgqt_mixed"</span><span class="p">;</span><span class="w">
    </span><span class="nx">TeXMain</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"notes/sgqt_mixed.tex"</span><span class="p">;</span><span class="w">
    </span><span class="nx">RenewCommands</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">@{</span><span class="w">
        </span><span class="s2">"figurefolder"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"."</span><span class="p">;</span><span class="w">
    </span><span class="p">};</span><span class="w">
    </span><span class="nx">AdditionalFiles</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">@{</span><span class="w">
        </span><span class="c"># TeX Stuff #</span><span class="w">
        </span><span class="s2">"notes/revquantum.sty"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"/"</span><span class="p">;</span><span class="w">
        </span><span class="s2">"figures/*.pdf"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"figures/"</span><span class="p">;</span><span class="w">
        </span><span class="c"># "notes/quantumarticle.cls" = $null</span><span class="w">

        </span><span class="c"># Theory and Experiment Support #</span><span class="w">
        </span><span class="s2">"README.md"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"anc/"</span><span class="p">;</span><span class="w">
        </span><span class="s2">"src/*.py"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"anc/"</span><span class="p">;</span><span class="w">
        </span><span class="s2">"src/*.yml"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"anc/"</span><span class="p">;</span><span class="w">

        </span><span class="c"># Experimental Data #</span><span class="w">
        </span><span class="s2">"data/*.hdf5"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"anc/"</span><span class="p">;</span><span class="w">

        </span><span class="c"># Other Sources #</span><span class="w">
        </span><span class="c"># We include this build script itself to provide an example</span><span class="w">
        </span><span class="c"># of using PoShTeX in pactice.</span><span class="w">
        </span><span class="s2">"Export-ArXiv.ps1"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">$null</span><span class="p">;</span><span class="w">
    </span><span class="p">};</span><span class="w">
    </span><span class="nx">Notebooks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">@(</span><span class="w">
        </span><span class="s2">"src/experiment.ipynb"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"src/theory.ipynb"</span><span class="w">
    </span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Breaking it down a bit, the section of the manifest between <code class="language-plaintext highlighter-rouge">#region</code> and <code class="language-plaintext highlighter-rouge">#endregion</code> is responsible for ensuring PoShTeX is available, and installing it if not.
This is the only “boilerplate” to the manifest, and should be copied literally into new manifest files, with a possible change to the version number <code class="language-plaintext highlighter-rouge">"0.1.5"</code> that is marked as required in our example.</p>

<p>The rest is a call to the PoShTeX command <code class="language-plaintext highlighter-rouge">Export-ArXivArchive</code>, which produces the actual ZIP given a description of the project.
That description takes the form of a PowerShell <em>hashtable</em>, indicated by <code class="language-plaintext highlighter-rouge">@{}</code>.
This is very similar to JavaScript or JSON objects, to Python <code class="language-plaintext highlighter-rouge">dict</code>s, etc.
Key/value pairs in a PowerShell hashtable are separated by <code class="language-plaintext highlighter-rouge">;</code>, such that each line of the argument to <code class="language-plaintext highlighter-rouge">Export-ArXivArchive</code> specifies a key in the manifest.
These keys are documented more throughly on the <a href="https://www.cgranade.com/posh-tex/">PoShTeX documentation site</a>, but let’s run through them a bit now.
First is <code class="language-plaintext highlighter-rouge">ProjectName</code>, which is used to determine the name of the final ZIP file.
Next is <code class="language-plaintext highlighter-rouge">TeXMain</code>, which specifies the path to the root of the TeX source that should be compiled to make the final arXiv-ready manuscript.</p>

<p>After that is the optional key <code class="language-plaintext highlighter-rouge">RenewCommands</code>, which allows us to specify another hashtable whose keys are LaTeX commands that should be changed when uploading to arXiv.
In our case, we use this functionality to change the definition of <code class="language-plaintext highlighter-rouge">\figurefolder</code> such that we can reference figures from a TeX file that is in the root of the arXiv-ready archive rather than in <code class="language-plaintext highlighter-rouge">tex/</code>, as is in our project layout.
This provides us a great deal of freedom in laying out our project folder, as we need not follow the same conventions in as required by arXiv’s AutoTeX processing.</p>

<p>The next key is <code class="language-plaintext highlighter-rouge">AdditionalFiles</code>, which specifies other files that should be included in the arXiv submission.
This is useful for everything from figures and LaTeX class files through to providing ancillary material.
Each key in <code class="language-plaintext highlighter-rouge">AdditionalFiles</code> specifies the name of a particular file, or a filename pattern which matches multiple files.
The values associated with each such key specify where those files should be located in the final arXiv-ready archive.
For instance, we’ve used <code class="language-plaintext highlighter-rouge">AdditionalFiles</code> to copy anything matching <code class="language-plaintext highlighter-rouge">figures/*.pdf</code> into the final archive.
Since arXiv requires that all ancillary files be listed under the <code class="language-plaintext highlighter-rouge">anc/</code> directory, we move things like <code class="language-plaintext highlighter-rouge">README.md</code>, the instrument and environment descriptions <code class="language-plaintext highlighter-rouge">src/*.yml</code>, and the experimental data in to <code class="language-plaintext highlighter-rouge">anc/</code>.</p>

<p>Finally, the <code class="language-plaintext highlighter-rouge">Notebooks</code> option specifies any Jupyter Notebooks which should be included with the submission.
Though these notebooks could also be included with the <code class="language-plaintext highlighter-rouge">AdditionalFiles</code> key, PoShTeX separates them out to allow passing the optional <code class="language-plaintext highlighter-rouge">-RunNotebooks</code> switch.
If this switch is present before the manifest hashtable, then PoShTeX will rerun all notebooks before producing the ZIP file in order to regenerate figures, etc. for consistency.</p>

<p>Once the manifest file is written, it can be called by running it as a PowerShell command:</p>
<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="o">.</span><span class="nx">/Export-ArXiv.ps1</span><span class="w">
</span></code></pre></div></div>
<p>This will call LaTeX and friends, then produce the desired archive.
Since we specified that the project was named <code class="language-plaintext highlighter-rouge">sgqt_mixed</code> with the <code class="language-plaintext highlighter-rouge">ProjectName</code> key, PoShTeX will save the archive to <code class="language-plaintext highlighter-rouge">sgqt_mixed.zip</code>.
In doing so, PoShTeX will attach your bibliography as a <code class="language-plaintext highlighter-rouge">*.bbl</code> file rather than as a BibTeX database (<code class="language-plaintext highlighter-rouge">*.bib</code>), since arXiv does not support the <code class="language-plaintext highlighter-rouge">*.bib</code> → <code class="language-plaintext highlighter-rouge">*.bbl</code> conversion process.
PoShTeX will then check that your manuscript compiles without the biblography database by copying to a temporary folder and running LaTeX there without the aid of BibTeX.</p>

<p>Thus, it’s a good idea to check that the archive contains the files you expect it to by taking a quick look:</p>
<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">ii</span><span class="w"> </span><span class="nx">sgqt_mixed.zip</span><span class="w">
</span></code></pre></div></div>
<p>Here, <code class="language-plaintext highlighter-rouge">ii</code> is an <em>alias</em> for <code class="language-plaintext highlighter-rouge">Invoke-Item</code>, which launches its argument in the default program for that file type.
In this way, <code class="language-plaintext highlighter-rouge">ii</code> is similar to Ubuntu’s <code class="language-plaintext highlighter-rouge">xdg-open</code> or macOS / OS X’s <code class="language-plaintext highlighter-rouge">open</code> command.</p>

<p>Once you’ve checked through that this is the archive you meant to produce, you can go on and upload it to arXiv to make your amazing and wonderful reproducible project available to the world.</p>

<h2 id="conclusions-and-future-directions">Conclusions and Future Directions</h2>

<p>In this post, we detailed a set of software tools for writing and publishing reproducible research papers.
Though these tools make it much easier to write papers in a reproducible way, there’s always more that can be done.
In that spirit, then, I’ll conclude by pointing to a few things that this stack <em>doesn’t</em> do yet, in the hopes of inspiring further efforts to improve the available tools for reproducible research.</p>

<ul>
  <li><strong>Template generation</strong>:
It’s a bit of a manual pain to set up a new project folder.
Tools like <a href="http://yeoman.io/">Yeoman</a> or <a href="https://github.com/audreyr/cookiecutter">Cookiecutter</a> help with this by allowing the development of interactive code generators.
A “reproducible arXiv paper” generator could go a long way towards improving practicality.</li>
  <li><strong>Automatic Inclusion of CTAN Dependencies</strong>:
Currently, setting up a project directory includes the step of copying TeX dependencies into the project folder.
Ideally, this could be done automatically by PoShTeX based on a specification of which dependencies need to be downloaded, <em>a la</em> pip’s use of <code class="language-plaintext highlighter-rouge">requirements.txt</code>.</li>
  <li><strong>arXiv Compatability Checking</strong>:
Since arXiv stores each submission internally as a <code class="language-plaintext highlighter-rouge">.tar.gz</code> archive, which is inefficient for archives that themselves contain archives, arXiv <em>recursively</em> unpacks submissions.
This in turn means that files based on the ZIP format, such as NumPy’s <code class="language-plaintext highlighter-rouge">*.npz</code> data storage format, are not supported by arXiv and should not be uploaded.
Adding functionality to PoShTeX to check for this condition could be useful in preventing common problems.</li>
</ul>

<p>In the meantime, even in lieu of these features, I hope that this description is a useful resource. ♥</p>

<!--

    NEXT POSTZES:

    - responding to referee reports using Pandoc
    - best practizes for gitzors
    - using signal to communicate w/ collabs

-->

<h2 id="acknowledgements">Acknowledgements</h2>

<ul>
  <li>A huge thanks to <a href="https://www.qc.uni-freiburg.de/team/daniel_suess">Daniel Suess</a> for writing the install instructions on macOS / OS X! ★♥★</li>
  <li>Thanks to <a href="https://twitter.com/o_guest">Olivia Guest</a> for <a href="https://twitter.com/o_guest/status/857641108729466883">suggestions on Git tutorials</a>.</li>
  <li>Thanks to Ben Barigola, Sarah Kaiser, and Chris Ferrie for feedback on drafts and for help testing.</li>
  <li>Thanks to Chris Ferrie for <a href="https://twitter.com/cgranade/status/857130965969358853">nerdsniping me</a> into writing this post.</li>
</ul>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/2017/03/31/what-we-encourage.html">
        What We Encourage
      </a>
    </h1>

    <span class="post-date">31 Mar 2017</span>

    <h3 id="tldr"><a href="https://github.com/tldr-pages/tldr-python-client" title="His tl;dr needs a tl;dr.">tl;dr</a></h3>

<ul>
  <li>What we encourage and incentivize has consequences, both direct and unseen.</li>
  <li>Those incentives often preclude progress on things we claim to value in academic research.</li>
  <li>Better tools and better institutional support can help.</li>
  <li>Hey, I made some crappy tools to point to a couple examples of incentives against reproducible research.</li>
</ul>

<h2 id="incentives">Incentives</h2>

<p>To a large extent, we do what we are encouraged to do. We are after all, more or less social agents, and respond the people and social systems around us as social agents. Examining what we are encouraged to do, and how we build incentive structures to reward some actions and people over others, is thus a matter of perpetual importance. To take one particularly stark example, <a href="https://www.cgranade.com/blog/2016/09/04/save-physics-from-physicists.html">I have argued here before</a> that sexual harassment and discrimination are at least as pervasive in physics as in many other fields of research. One way to combat this, then, is to develop incentive structures that do not further reinforce inequality but instead make it more difficult to use scientific institutions to harass and attack. Thus, we can use tools such as codes of conduct, effective reporting at institutions, and backchannel communication to build better systems of incentives that encourage positive behavior. As a side note, this is especially critical as science funding is under imminent and unprecedented attack in the United States— we’ve seen that public outcry can have magnificent effects for protecting institutions and funding, such that we must ensure that we earn the public support we now so existentially require.</p>

<p>Having thus seen that systems of encouragement can be social, it’s also important to realize that encouragement can come as well in the form of technical constraints imposed by the systems that we build and interact with. To take one particular and relatively small example, the <a href="http://matlabsadness.tumblr.com/post/46228191810/one-function-per-m-file">one-function-per-file</a> design decision of MATLAB <em>encourages</em> users to write longer functions than they might otherwise in a different language. In turn, this makes it harder for MATLAB users to <a href="http://neuroplausible.com/matlab">transfer skills to software development in other languages</a>, <em>discouraging</em> diversity in software tools.</p>

<p>Even though the design decisions made by MATLAB can be often be circumvented by users who disagree, they has a significant impact on what kind of software design decisions get made. For instance, using MATLAB affects how code is shared as well as how APIs are designed. These decisions can in turn also compound with social encouragements; consider the magnification of this example, given the near-exclusive focus on proprietary tools such as MATLAB found in many undergraduate physics programs. That is, our approach to physics education encourages certain software development methodologies over others as an immediate consequence of teaching particular tools rather than methods.</p>

<p>The interaction between social and technical encouragements is widely recognized. In user interface and user experience design, for instance, the concept of an <a href="https://medium.com/@WebdesignerDepot/how-to-perfect-ux-with-design-affordances-79ce78792b08#.tfo7tvoif"><em>affordance</em></a> is used to encourage a user to some set of interactions with a technical system. This understanding can be leveraged as a powerful tool for <em>persuading</em> users both to benefitial and malicious ends, as has been <a href="https://www.amazon.com/Persuasive-Technology-Computers-Interactive-Technologies/dp/1558606432">prominently argued for at least fifteen years</a>. Critically reflecting on how social and technical encouragements combine to affect our behavior is accordingly a pressing issue across different disciplines.</p>

<h2 id="state-of-the-art">State of the Art</h2>

<p>Examining physics methodologies in detail from the perpsective of incentives, let’s then consider what kinds of encouragement we create with our design choices and with our research methodologies by examining a few relevant examples. Importantly, none of these examples represent criticism of individual users or research groups, but rather an examination of what incentives users and groups are under.</p>

<ul>
  <li>
    <p><em>Experiment control and analysis</em>: Current expeirmental methodology in physics often concerns itself with <em>ad hoc</em> control systems developed internally by graduate and undergraduate students in a single group. This discourages collaboration between groups using different internal systems, and more critically, can discourage challenging assumptions built in to early stages of experimental control systems. Efforts such as <a href="https://github.com/Galvant/InstrumentKit">InstrumentKit</a>, <a href="https://github.com/Ulm-IQO/qudi">Qudi</a>, and <a href="http://qcodes.github.io/Qcodes/">QCoDeS</a>, <a href="https://github.com/mabuchilab/Instrumental">Instrumental</a>, <a href="https://github.com/0/SpanishAcquisition">SpanishAquisition</a>, and <a href="http://labscriptsuite.org/">Labscript</a> have attempted to change these incentives by instead providing high-quality open source libraries that can work <em>across</em> groups, and hence remove disincentives that can impede collaboration. Collecting common functionality in this way also encourages contributing safety and correctness features that would otherwise be undervalued in a single <em>ad hoc</em> application.</p>
  </li>
  <li>
    <p><em>Statistical analysis</em>: Common software tools such as MATLAB, SciPy, and Mathematica all provide “curve fitting” functionality by default, and report frequentist metrics on the results produced by “curve fitting.” This ready availability encourages the use of “fitting” over other methodologies, even in cases where the theory behind “fitting” does not apply. Taken in conjunction with the reticence of reviewers to point out such methological problems, it isn’t a stretch to say that we directly encourage the publication of incorrect research results by failing to provide easy-to-use and principled statistical analysis tools that match experimental models.</p>
  </li>
  <li>
    <p><em>Collaboration and version control</em>: At least ideally, collaboration forms a cornerstone of scientific research. Accordingly, the writing and editing of research manuscripts is also ideally a collaborative effort. To support that, we often employ software tools such as Dropbox to synchronize changes between collaborators. The technical restrictions imposed by Dropbox, however, present their own encouragements and discouragements. For example, that Dropbox will overwrite changes made concurrently by two users discourages authors from editing on disjoint sections. Often, this is mitigated by social agreements such as “tokens,” where authors agree only to edit a work if they hold the “token” for the TeX source. That Dropbox does not present version history in a consise and readable form also discourages focusing editing efforts on recent changes. The eagerness of Dropbox to share temporary and editor-specific files also discourages the use of modern text editors such as <a href="https://atom.io/">Atom</a>, <a href="https://www.sublimetext.com/">Sublime Text</a> and <a href="https://code.visualstudio.com/">VS Code</a>, each of which uses machine-specific metadata to store information such as undo history. Though these issues can somewhat be mitigated by using formal version control systems such as Git or Mercurial, that many students and postdocs have little to no opportunity to learn such tools presents a strong <em>social</em> discouragement against robust and efficient collaboration.</p>
  </li>
  <li>
    <p><em>Plotting and accessibility</em>: Approximately 10% of the population is at least mildly color-blind such that the use of colors in scientific visualizations can prevent a significant barrier to accessibility. Default color schemes in widely-used tools such as MATLAB <em>discourage</em> accessible design by forcing users to specify that each plot individually should use an accessible palette. Up until recently, the Matplotlib plotting library for Python has similarly discouraged accessible design, though other positive encouragements such as declarative style sheets have somewhat mitigated this.</p>
  </li>
</ul>

<h2 id="open-science">Open Science</h2>

<p>One critical component common to each of these examples is that they use the concept of open source software development to change the incentives for researchers. If it becomes easier — if we encourage — contributing to existing efforts instead of reinventing well-understood wheels, then not only does it become less expensive to do cutting-edge research, but it also becomes more practical to do <em>reproducible</em> research. As we can see from reproducibility crises in other fields, physics research likely cannot survive its current model of closed-source closed-data closed-analysis papers hidden behind increasingly-expensive paywalls. Perhaps most critically, the lack of reproducibility in scientific papers can also play a role in <a href="http://www.factcheck.org/2017/02/no-data-manipulation-at-noaa/">exacerbating public mistrust of science</a>. I’ll return to the role that the arXiv plays in changing these incentives later, but suffice to say that open access is not sufficient to imply that a paper or other research output can be independently assessed for correctness. The gap between the openness we currently take as being standard in physics and the level of transparency that we need is thus not a trivial one.</p>

<p>In this discussion, of course, we also cannot afford to elide that open science in general and open source in particular also helps to remove elements of gatekeeping that can be used to preclude participation. In current practice, the expense of performing physics research, be it theory or experiment, naturally concentrates decision-making power in a smaller number of individuals. Though the effects of this concentration can be mitigated to some degree, it is also important to reduce the areas in which cognative biases can hide from critical examination. Reducing barriers to entry can provide a way to do so.</p>

<p><abbr title="Not only does he have a point, he actually got to it eventually!">I posit</abbr> that these self-same barriers to entry are, perhaps ironically, one of the largest impediments to the adoption of open science methodologies in physics. Take, for instance, <a href="http://academia.stackexchange.com/a/86538/70648">the advice offered to me</a> in response to a question about how to adopt better open science methods when posting to the arXiv:</p>

<blockquote>
  <p>For the sake of persistent archiving you should put all ancillary material at a sustainably archived website specifically designed to preserve scholarly communications material e.g. Zenodo https://zenodo.org/ or Dryad http://datadryad.org/ or Figshare https://figshare.com/</p>
</blockquote>

<p>I agree with this advice entirely, and have in fact advocated this exact approach with both <a href="http://qinfer.org/">open-source efforts</a> and <a href="https://arxiv.org/abs/1605.05039">reproducible papers</a>. That said, let’s consider the incentive structure imposed by this approach. A student or postdoc taking responsibility for posting a reproducible work to the arXiv must then not only know how to do so directly, including how to write <a href="https://en.wikipedia.org/wiki/Literate_programming">literate source code</a>, but also about the existence of services such as Figshare. Moreover, a researcher must then manage their work’s presence on arXiv as well as additional services, increasing the complexity of maintaining an accessible research output.</p>

<p>Happily, however, arXiv itself <a href="https://arxiv.org/help/ancillary_files">supports including ancillary material</a> such as source code and data along with a paper. Even here, though, the workflow for providing such ancillary material is more complicated than the comparable closed-science workflow. In particular, arXiv identifies ancillary material as being those files included in the <code class="language-plaintext highlighter-rouge">anc/</code> subfolder of a submission package, but subfolders are only supported by uploading a ZIP archive of the entire submission. To make such a ZIP file with most existing tools, the original file must itself be in a folder called <code class="language-plaintext highlighter-rouge">anc/</code>, imposing a nontrivial technical restriction on project folder structures.</p>

<p>To some degree, encouragements of this kind that run counter to open science goals are inevitable. Indeed, there is a bit of a contradiction in that the very goal of reproducible research is to make it more difficult to publish in a way that is disporportionate between papers that are likely correct and those that cannot be as easily assessed for correctness. The natural tendency, then, is for reproducibility advocates <a href="https://twitter.com/csferrie/status/841607819224743936">to yell into the void or into the echo chamber</a> about the existential importance of open science, and for the rest of the community to go forth with their business in the best way that they can given very limited resources.</p>

<p>In the same way as in dealing with discrimination by providing better tools that change incentive structures, we can break this circularity by providing better tools for writing reproducible papers. For instance, one very impressive tool to do precisely this is <a href="https://www.reprozip.org/">ReproZip</a>, which works by leveraging modern software and hardware engineering technologies such as virtual machines. Indeed, ReproZip works great at making it easier to provide compact descriptions of reproducible research projects. This approach works especially well in combination with tools such as <a href="http://jupyter.org/">Jupyter Notebook</a>, which allow for producing standardized and well-understood literate source code for a variety of different languages. Though Jupyter is perhaps most famous for its Python support, having grown out of the IPython project, it also supports <a href="https://github.com/JuliaLang/IJulia.jl">Julia</a>, <a href="https://github.com/IRkernel/IRkernel">R</a>, <a href="https://github.com/fsprojects/IfSharp">F#</a>, and even <a href="https://github.com/Calysto/matlab_kernel">MATLAB</a> when augmented with simple-to-install extensions.</p>

<p>Recently, I have started to experiment with other software tools for changing incentive structures, in the hopes of building on the backs of these efforts. My goals are of course more modest, in keeping with the resources available, but at the least I would like to propose ways of making tools such as Jupyter Notebook more accessible to arXiv users. In the rest of this post, I will detail two such (experimental!) efforts and how they are each motivated by reducing barriers to entry for reproducible physics research.</p>

<h2 id="revquantum"><code class="language-plaintext highlighter-rouge">{revquantum}</code></h2>

<p>The first such effort is the <code class="language-plaintext highlighter-rouge">{revquantum}</code> style file for LaTeX, intended to make it easier to write reproducible and accessible papers in the <code class="language-plaintext highlighter-rouge">{revtex4-1}</code> and <a href="https://github.com/cgogolin/quantum-journal"><code class="language-plaintext highlighter-rouge">{quantumarticle}</code></a> document classes. The <code class="language-plaintext highlighter-rouge">{revquantum}</code> package supports accessiblility in a number of different ways:</p>

<ul>
  <li>
    <p><em>Semantic notation</em>: <code class="language-plaintext highlighter-rouge">{revquantum}</code> provides commands such as <code class="language-plaintext highlighter-rouge">\newoperator</code>, which allow users to write in a more semantic fashion than worrying about implementation details. In that example, <code class="language-plaintext highlighter-rouge">\newoperator{Tr}</code> defines <code class="language-plaintext highlighter-rouge">\Tr</code> as <code class="language-plaintext highlighter-rouge">\newcommand{\Tr}{\operatorname{Tr}}</code>, resulting in more readable code than what might be produced directly, such as <code class="language-plaintext highlighter-rouge">\mathrm{Tr}(\rho)</code>.</p>
  </li>
  <li>
    <p><em>Accessible color palettes</em>: <code class="language-plaintext highlighter-rouge">{revquantum}</code> also provides definitions for the <a href="jfly.iam.u-tokyo.ac.jp/color/">Color Universal Design</a> palette, such that users can quickly set colors for TikZ diagrams and other features in an accessible manner.</p>
  </li>
  <li>
    <p><em><code class="language-plaintext highlighter-rouge">{listings}</code> integration</em>: The <code class="language-plaintext highlighter-rouge">{listings}</code> package provides invaluable tools for including source code along with research manuscripts. There are some subtle issues in integrating <code class="language-plaintext highlighter-rouge">{listings}</code> with <code class="language-plaintext highlighter-rouge">{revtex4-1}</code> and other such classes, however, such that <code class="language-plaintext highlighter-rouge">{revquantum}</code> provides a reasonable set of defaults that for use with <code class="language-plaintext highlighter-rouge">{revtex4-1}</code>.</p>
  </li>
  <li>
    <p><em>Package compatibility warnings</em>: There are a few commonly-used packages which are known to be incompatible with <code class="language-plaintext highlighter-rouge">{revtex4-1}</code>. These incompatibilities can cause difficult-to-diagnose errors, however, instead of immediately raising errors that identify the problem. To address this and prevent users from being discouraged against modular TeX design, <code class="language-plaintext highlighter-rouge">{revquantum}</code> will raise warnings or errors when incompatible packages are loaded so that users are immediately informed as to the issue.</p>
  </li>
  <li>
    <p><em>Bibliography improvements</em>: The default BibTeX style file provided with <code class="language-plaintext highlighter-rouge">{revtex4-1}</code> suppresses the titles of cited papers in order to match the formatting that might appear in PRL and similar journals. For deployment to the arXiv, though, where space constraints are much less of an issue, this design decision removes context from the reader and encourages more of a focus on where something is published than the content that is being cited. To address this and encourage a stronger focus on research content, <code class="language-plaintext highlighter-rouge">{revquantum}</code> sets a default configuration that provides more context in generated bibliographies. Moreover, <code class="language-plaintext highlighter-rouge">{revquantum}</code> changes citation URLs to default to HTTPS, encouraging better security practices.</p>
  </li>
  <li>
    <p><em>Annotations for collaborative writing</em>: Finally, <code class="language-plaintext highlighter-rouge">{revquantum}</code> provides new lightweight commands such as <code class="language-plaintext highlighter-rouge">\todo</code> and <code class="language-plaintext highlighter-rouge">\citeneed</code> for annotating remaining tasks in a collaborative document. These commands leave warnings in the log file, making them easy to identify in modern text editors that annotate warnings in the TeX source. Moreover, the <code class="language-plaintext highlighter-rouge">[final]</code> option ot <code class="language-plaintext highlighter-rouge">{revquantum}</code> promotes these warnings to errors, providing a safety check against leaving outstanding tasks.</p>
  </li>
</ul>

<h2 id="poshtex">PoShTeX</h2>

<p>The other effort I would like to detail a bit here is <a href="https://www.cgranade.com/posh-tex/">PoShTeX</a>, a set of PowerShell tools for working with TeX-based research projects. In particular, PoShTeX provides the <code class="language-plaintext highlighter-rouge">Export-ArXivArchive</code> command, which makes a ZIP archive suitable for uploading to arXiv. In doing so, PoShTeX will rebuild the current TeX file, and will optionally re-run any nominated Jupyter Notebooks to ensure consistency with the figures and descriptions provided in the project’s main text. For example, a project might include a short <code class="language-plaintext highlighter-rouge">Export-ArXiv.ps1</code> script to produce an arXiv-compatible archive:</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#region Bootstrap PoShTeX</span><span class="w">
</span><span class="nv">$modules</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Get-Module</span><span class="w"> </span><span class="nt">-ListAvailable</span><span class="w"> </span><span class="nt">-Name</span><span class="w"> </span><span class="nx">posh-tex</span><span class="p">;</span><span class="w">
</span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="nv">$modules</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="n">Install-Module</span><span class="w"> </span><span class="nx">posh-tex</span><span class="w"> </span><span class="nt">-Scope</span><span class="w"> </span><span class="nx">CurrentUser</span><span class="p">}</span><span class="w">
</span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="p">(</span><span class="nv">$modules</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="nf">?</span><span class="w"> </span><span class="p">{</span><span class="bp">$_</span><span class="o">.</span><span class="nf">Version</span><span class="w"> </span><span class="o">-ge</span><span class="w"> </span><span class="s2">"0.1.4"</span><span class="p">}))</span><span class="w"> </span><span class="p">{</span><span class="n">Update-Module</span><span class="w"> </span><span class="nx">posh-tex</span><span class="p">}</span><span class="w">
</span><span class="n">Import-Module</span><span class="w"> </span><span class="nx">posh-tex</span><span class="w"> </span><span class="nt">-Version</span><span class="w"> </span><span class="s2">"0.1.4"</span><span class="w">
</span><span class="c">#endregion</span><span class="w">

</span><span class="n">Export-ArXivArchive</span><span class="w"> </span><span class="nt">-RunNotebooks</span><span class="w"> </span><span class="p">@{</span><span class="w">
    </span><span class="nx">ProjectName</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"my-little-pauli"</span><span class="p">;</span><span class="w">
    </span><span class="nx">TeXMain</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"my-little-pauli.tex"</span><span class="p">;</span><span class="w">
    </span><span class="nx">AdditionalFiles</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">@{</span><span class="w">
        </span><span class="s2">"fig/*.pdf"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"fig/"</span><span class="p">;</span><span class="w">
        </span><span class="s2">"data/tomography-data.hdf5"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">$null</span><span class="p">;</span><span class="w">
        </span><span class="s2">"revquantum.sty"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">$null</span><span class="p">;</span><span class="w">
    </span><span class="p">};</span><span class="w">
    </span><span class="nx">Notebooks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">@(</span><span class="w">
        </span><span class="s2">"src/fidelity_is_magic.ipynb"</span><span class="w">
    </span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>This script will then install PoShTeX if it is not already available, and will then rerun the listed notebooks, compile the TeX output, and produce the final build file <code class="language-plaintext highlighter-rouge">my-little-pauli.zip</code> for uploading to arXiv. In this way, PoShTeX makes it very straightforward to include reproducible material.</p>

<p>The second major functionality provided by PoShTeX is that it makes it much easier to write reusable LaTeX resources such as style files by making it easy to write installers and produce CTAN-compatible archives. This is, for example, how <code class="language-plaintext highlighter-rouge">{revquantum}</code> is packaged and uploaded to CTAN. Thus, PoShTeX hopefully also encourages not only sharing the research code itself but also the LaTeX code used to produce legible and readable research documents.</p>

<p>By the way, why PowerShell? It may seem like an odd choice for encouraging open scientific research, but consider that a very significant majority of Windows users already have PowerShell, given its status as a built-in tool since Windows 7. Though bash enjoys even wider deployment on macOS / OS X and on Linux, the [recent availability of PowerShell as an open source tool] on non-Windows platforms changes this calculus dramatically. In particular, given the ease of installing PowerShell modules with the <code class="language-plaintext highlighter-rouge">Install-Module</code> command, PowerShell may offer a way forward to distribute cross-platform shell libraries in an easy-to-use way.</p>

<h2 id="concluding-remarks">Concluding Remarks</h2>

<p><abbr title="Long post is long…">In this post</abbr>, I’ve described a few ways that what we encourage can have dramatic negative or hopefully positive effects on research culture and practice. These examples all speak to how thinking not only critically but also systematically can provide a path forward for doing the best science that we can.</p>

  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/blog/page3">Older</a>
  
  
    
      <a class="pagination-item newer" href="/">Newer</a>
    
  
</div>
    </div>

  </body>
</html>
